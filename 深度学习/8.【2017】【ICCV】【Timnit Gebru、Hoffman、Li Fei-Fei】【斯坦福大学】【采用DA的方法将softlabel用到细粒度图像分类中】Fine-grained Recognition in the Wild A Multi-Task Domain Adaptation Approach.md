## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\8.【2017】【ICCV】【Timnit Gebru、Hoffman、Li Fei-Fei】【斯坦福大学】【采用DA的方法将softlabel用到细粒度图像分类中】Fine-grained Recognition in the Wild A Multi-Task Domain Adaptation Approach.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**细粒度的图像识别：**文章主要是做细粒度的图像识别，通常来说图像识别只用识别这是车，这是鸟，细粒度的图像识别就是要不仅识别出鸟，还要识别出这是什么种类的鸟，不仅识别出车，还要识别出这是什么牌子的车。

**背景**：**无监督或者半监督**，现在图像识别方法是全监督的，样本其实不难获得，最大的问题是数据集与真实世界的样本有偏差，所以我们研究了细粒度域适应，主要是克服数据集和真实世界之间的偏移。

论文使用容易标记的样本，研究domain adaptation解决易获取样本与自然场景样本数据集转换的问题。这其中多任务的属性学习被用来提升性能。

**主要是将soft label判别器加入细粒度识别任务。**细粒度识别就是比较精细的图像识别，比如识别的是不同品种的狗，不同牌子的汽车等。

## 2. 网络结构

### 2.1 网络结构

这篇文章受到[13.【是零样本学习ZSL的开山之作，为类标签引入属性标签，来预测训练集没有的未知类】【Christoph H. Lampert】Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer](C:\Users\Emoaya\Desktop\文章\13.【是零样本学习ZSL的开山之作，为类标签引入属性标签，来预测训练集没有的未知类】【Christoph H. Lampert】Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer.pdf)的启发

文章的网络结构基于：[6.【用对抗对齐特征用软标签对齐类别】【Eric Tzeng、Hoffman】Simultaneous Deep Transfer Across Domains and Tasks](C:\Users\Emoaya\Desktop\文章\6.【用对抗对齐特征用软标签对齐类别】【Eric Tzeng、Hoffman】Simultaneous Deep Transfer Across Domains and Tasks.pdf)如下图

![image-20221018193507962](D:\markdown file\截图\image-20221018193507962.png)

这是本文的网络结构：

![image-20221018194513523](D:\markdown file\截图\image-20221018194513523.png)

![image-20220928132419772](D:\markdown file\截图\image-20220928132419772.png)

其主要原理是引入了多个损失函数来**监督/约束**模型训练，主要面向**无监督或者半监督**的域适应任务。具体的网络结构图如图所示。

从图中可以看出，网络是一个双分支的网络，分别接受源域和目标域的数据为输入，其分别输出若干分支输出，其中一个分支输出**细粒度类别**，其余输出**属性类别**（如外观是什么？颜色是什么？）

### 2.2 损失函数

其损失函数大致分为四类：（1）有监督损失（2）无监督适应损失（3）半监督适应损失（4）属性一致性损失。

![image-20220929120614962](D:\markdown file\截图\image-20220929120614962.png)

![image-20220929120723228](D:\markdown file\截图\image-20220929120723228.png)

![image-20220929120730743](D:\markdown file\截图\image-20220929120730743.png)

![image-20220929120738670](D:\markdown file\截图\image-20220929120738670.png)

- 就**有监督损失**而言，在源域数据训练时起作用。也就是对细粒度分类时采用了一个细粒度类别的softmax损失，对每个属性分类均采用了各自的softmax损失。（1）式表示对于单个属性α的CE损失，单个属性α有α~K~个类别，所以单个属性α要进行α~K~分类任务，y~α~是对于输入样本x的α属性的标签，p~α~ = [p~α1~, ...p~αK~]是经过softmax后α属性下的α~K~个类别对应的概率。（2）式表示对于细粒度图像分类的CE损失，有K个类别，所以要进行K分类任务，y是对于输入样本x的标签，p = [p~1~, ...p~K~]是经过softmax后K个类别对应的概率。（3）式将上面两个损失函数进行汇总，分别是1个细粒度图像分类损失+N~α~个属性损失函数。

![image-20220929143303519](D:\markdown file\截图\image-20220929143303519.png)

- 就**无监督适应损失**而言，主要为了实现**域对齐**。作者采用了domain confusion loss。

![image-20220929143341846](D:\markdown file\截图\image-20220929143341846.png)

- 就**半监督适应损失**而言，只有当目标域有（部分）标签时起作用。采用**源域**中细粒度类别的soft label和属性的soft label对目标域的细粒度类别和属性学习进行监督。**这里用到了DA的内容**

  ![image-20220929131548340](D:\markdown file\截图\image-20220929131548340.png)

![image-20220928161135531](D:\markdown file\截图\image-20220928161135531.png)

![image-20220929135507913](D:\markdown file\截图\image-20220929135507913.png)

- 就**属性一致性损失ACL**而言，说简单点，就是“**对齐**”细粒度分类器对某个属性的预测概率和属性分类器对这个属性的预测概率。这里就**属性一致性损失ACL**展开来说，不妨以鸟的细粒度分类为例。为了获得网络输出的细粒度类别概率分布（图2左上）中**隐含的属性分布**（图2右上），比如我们要从鸟的细粒度分类任务中找到“外形大小=小”这个属性概率，我们只需要将所有拥有“外形大小=小”的类别（如蜂鸟等）对应的细粒度类别概率分布取平均即可（如图2左上到右上的过程）。其训练的监督信息就是**网络在该属性上输出的概率分布（图2右下）**。这个属性一致性损失由**对称的KL散度**构成，定义如上，其中p~α~是属性α的概率分布，p~α~_hat是由细粒度类别的概率分布。

### 2.3 与DA相关的内容

![image-20220929143727470](D:\markdown file\截图\image-20220929143727470.png)

就是红圈的部分与DA相关，主要是无监督、半监督的情况。