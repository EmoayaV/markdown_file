[TOC]

## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\1.【2018】【Neurocomputing】【wang mei】【北邮】【DA综述】Deep Visual Domain Adaptation A Survey.pdf)

### 1.1 在干什么、有什么贡献、结论是什么

![image-20220902131353654](D:\markdown file\截图\image-20220902131353654.png)

总结了深度DA的技术，深度DA的方法可以分为单步和多步，单步最多，然后可以分为同构和异构，最后还可以细分为无监督、半监督和监督。

提出了现有深度DA技术的不足：1. 现在大多数方法都是基于同构，就是假设源域和目标域的特征空间是相同的。2. 大多数深度DA都是做图像分类，但是很少有人做目标检测，人脸识别，语义分割等任务。3. 如何在小数据集上完成任务是个挑战。4. 如何在标签不同的目标域和源域做深度DA是个问题。

## 2. 概览overview

### 2.1 定义和符号

**域** $\mathcal{D}$ 由**特征空间** $\mathcal{X}$ 和边缘概率分布 **P(X)** 组成，其中 **X = {x~1~, x~2~, ... , x~n~} ∈ $\mathcal{X}$**，**X** 是样本的集合，每个样本的特征都在特征空间 $\mathcal{X}$ 上，所以域可以表示为 **$\mathcal{D}$ = {$\mathcal{X}$, P(X)}**，也就是说域由特征，和在样本里这些特征出现的概率组成。

**任务** $\mathcal{T}$由特征空间 $\mathcal{Y}$ 和目标预测函数 **f( · )** 组成，也可以看作条件概率 **P(Y|X)** 。

通常我们用有标签的数据 **{x~i~, y~i~}** 通过监督学习的方式去学习 **P(Y|X)** ，其中 **x~i~ ∈ $\mathcal{X}$, y~i~ ∈ $\mathcal{Y}$**。

DA中主要有两个域，**源域和目标域**，分别用 **{$\mathcal{X}$^s^, P(X)^s^}, {$\mathcal{X}$^t^, P(X)^t^}** 表示，源域通常是由大量有标签的数据组成，目标域通常由少量有标签或者大量无标签的数据组成。

**同构DA**，指特征空间相同，类别相同，数据分布不同。

**异构DA**，指特征空间或者类别不同，或者两者都不同，

## 3. DA的方法(主要是单步DA的方法)

文献综述中将DA方法主要分为

- **One-step DA**
- **Multi-step DA**

其主要区别体现在：

- **One-step DA**是假设**源域**（source domain）和**目标域**（target domain）是相关的，但是可能**域分布**存在一些差异，需要通过调整域间的分布（一步）实现域适应。
- **Multi-step DA**是假设**源域**（source domain）和**目标域**（target domain）是无关的（更符合现实）。该类方法主要通过在源域和目标域之间建立一些桥梁（中间域），（多步）实现域适应。

单步DA方法又可以细分为同构和异构的方法，实际中研究单步DA方法的居多，所以**主要介绍单步DA的方法。**

![image-20220902131353654](D:\markdown file\截图\image-20220902131353654.png)

![image-20220904134748418](D:\markdown file\截图\image-20220904134748418.png)

![image-20220905120315612](D:\markdown file\截图\image-20220905120315612.png)

### 3.1 单步DA方法概述

* **基于差异的DA方法（Discrepancy-based DA）**

主要是用fine-tune的技术，其中**Discrepancy-based方法还可以继续分为四小类**， Class criterion、statistic criterion、architecture criterion 和 geometric criterion

这类方法主要利用微调（finetune）网络参数降低域偏移（domain shift）。

* **基于生成的DA方法（Adversarial-based）**

主要通过一个二分类器区分数据是来自源域还是目标域，网络要做的是骗过这个二分类器，当二分类器不能区分数据是来自源域还是目标域时，就拉近了源域和目标域的距离。

分为生成方法（Generative Models）和非生成方法（Non-Generative Models）。

这类方法引入了判别器，并引入对抗损失来使得**源域和目标域**使得域判别器难以分辨（也就是混淆域判别器），那么源域和目标域就靠的足够近了。

* **基于重构的DA方法（Reconstruction-based）**

假设源或目标样本的数据重构可有助于提高DA的性能。 重构器可以确保域内表示的特异性和域间表示的可分辨性。

分为编码器解码器重构（Encoder-Decoder Reconstruction）和对抗重构（Adversarial Reconstruction）。

这类方法为了保证域适应过程中图片信息的完整性，通常将数据重建（保证重建误差最小）作为域适应过程中另一辅助任务。

**研究现状**

![image-20220917134332729](D:\markdown file\截图\image-20220917134332729.png)

在DA，人们集中去做无监督的DA方法，在上面三个方法中基于差异的已经做了许多年了，基于生成和重构的DA方法做的人不多。

### 3.2 基于差异的DA方法（Discrepancy-based DA）

![image-20220904134748418](D:\markdown file\截图\image-20220904134748418.png)

#### 3.2.1 基于类准则的方法（Class Criterion）

基于class criterion的方法主要采用**类别标签信息**去引导模型实现不同域之间的知识迁移。

如果目标域中的样本**有标签**（有监督学习），那么通常采用一些**软标签**（soft label）或者**度量学习**（metric learning）的方式来进行学习。

如果目标域中的样本**没有标签**（无监督学习），可以采用制造**伪标签**（pseudo label）或者**属性表示**（attribute representation）作为类别信息。

那么这样下来，现有基于class criterion的方法可以再次划分为**四个小小类**，分别为

- **基于Soft label**
- **基于metric learning**
- **基于attribute representation**
- **基于pseudo label**

##### 3.2.1.1 基于Soft label 软标签的方法

*在了解基于Soft label的方法之前，我们先了解一下何为soft label。所谓的label就是我们在进行网络训练时候的**监督信息**，比如在分类任务中就是一个个one-hot编码。*

*比如猫狗人三分类任务中，我们可以用“001”表示猫，“010”表示狗，“100”表示人。当然了，这种one-hot标签显然就是**硬标签**（hard label），因为它无法反映类别之间的关系。*

*比如相比人来说，猫和狗的共同之处还是蛮多的，也就是在预测一张“狗图”的时候，可能会产生“0.09-0.9-0.01”这个结果的，这个“0.09-0.9”与“0.9-0.01”其实是不同的，这说明“猫狗”之间的近似度可能是远大于“狗人”的。这个“0.09-0.9-0.01”其实就包含了一定的类别关系，故这种表示形式就是**软标签**（soft label）。*

###### [5.【知识蒸馏 软标签】【Hinton】Distilling the Knowledge in a Neural Network](./5.【2015】【知识蒸馏 软标签】【Hinton】Distilling the Knowledge in a Neural Network.md)

![image-20220920172156516](D:\markdown file\截图\image-20220920172156516.png)

> 这篇文章就提到了利用**软标签**进行知识压缩与蒸馏来从一个或者多个大型模型中学到一个小型网络，并且这个小模型还保持了这些大模型的**知识存储**，这样就为模型压缩等任务提供了很多可能性了。具体网络图（已标注图源）如图所示。
>
> 该模型的大致思路就是在一个训练完毕的大型模型的最后softmax层前对特征按位除以一个T，进而获得输出的**软标签**。接着用这个**软标签**作为一个小型模型的**部分监督信息**，图中作者也用到部分**硬标签**进行学习。这样的软硬结合方式可以有效提高模型的收敛速度。

###### [6.【用对抗对齐特征用软标签对齐类别】【Eric Tzeng、Hoffman】Simultaneous Deep Transfer Across Domains and Tasks](./6.【2015】【用对抗对齐特征用软标签对齐类别】【Eric Tzeng、Hoffman】Simultaneous Deep Transfer Across Domains and Tasks.md)

![image-20220927182651889](D:\markdown file\截图\image-20220927182651889.png)

> 本文提出的模型的结构图如下，该模型由两个**共享权重**的Siamese网络（说到底就是一个网络）构成。在实现特征提取后，为了使得源域和目标域在特征空间的距离缩小，作者提出了domain confusion loss来使得这两个域在特征空间难以被识别出来，这就相当于降低了domain shift，进而促使模型学到domain-invariant特征。
>
> 不仅如此，作者在这边文章主要做了两件事，其一就是domain transfer，这就是上面提到的用domain confusion loss进行训练达到**域的迁移**。其二是task transfer，作者在这里应用了**源域**上获得的软标签对**目标域**的学习过程进行监督。
>
> 为什么作者要这么做呢？
>
> 作者提到最大化domain confusion可以使得源域和目标域的边缘分布尽可能近，但是这不一定会使得**目标中的类别进行对齐**。这个很好理解，也就是虽然源域和目标域靠的很近，但是源域中的**类别分布**和目标域的**类别分布**重合的概率可能很小。
>
> 为了保证域间距离最小的同时，使得**类别分布也尽可能的靠近**。作者引入了**源域软标签**（因为源域软标签包含了源域中各类别的关系）作为网络在目标域学习过程中类别分布的监督信息，进而实现了task transfer。

###### [8.【采用DA的方法将softlabel用到细粒度图像分类中】【Timnit Gebru、Hoffman、Li Fei-Fei】Fine-grained Recognition in the Wild A Multi-Task Domain Adaptation Approach](./8.【2017】【采用DA的方法将softlabel用到细粒度图像分类中】【Timnit Gebru、Hoffman、Li Fei-Fei】Fine-grained Recognition in the WildA Multi-Task Domain Adaptation Approach.md)

![image-20220929143727470](D:\markdown file\截图\image-20220929143727470.png)

> 其主要原理是引入了多个损失函数来**监督/约束**模型训练，主要面向**无监督或者半监督**的域适应任务。具体的网络结构图如图所示。
>
> 从图中可以看出，网络是一个双分支的Siamese网络，分别接受源域和目标域的数据为输入，其分别输出若干分支输出，其中一个分支输出**细粒度类别**，其余输出**属性类别**（如外观是什么？颜色是什么？）
>
> 就**半监督适应损失SSA**而言，只有当目标域有（部分）标签时起作用。采用**源域**中细粒度类别的soft label和属性的soft label对目标域的细粒度类别和属性学习进行监督。

##### 3.2.1.2 基于metric learning度量学习的方法

*在机器学习中，关于度量的学习，一直以来是一个重要的研究方向。如何度量两个样本之间的距离，看似是一个简单的问题，实则关乎到几乎所有的分类、回归、聚类等基本任务的表现。好的度量有助于我们发现更好的特征，构建更好的模型。什么是度量？英文名叫做Metric，就是距离的意思。我们**常用的欧氏距离**、马氏距离、**余弦相似度**等，都可以叫做度量。这些度量是**显式**的，是不需要学习直接就可以计算出来的。但是，在特定的任务中，单纯地运用这些简单的距离公式，往往达不到我们预期的效果。此时，一种对于度量的研究就可以帮助我们对这些距离进行**学习**。此时，这个距离则是隐式的。这就是所谓的**度量学习 (Metric Learning)**。*

*度量学习的基本思路是，给定一些训练样本，这些样本中包含了我们预先观测到的一些对于样本的知识（先验），例如，哪两个样本的距离应该要近一些，哪两个要远一些。然后，我们的学习算法就可以以这些先验知识为约束条件，构建目标函数，学习到这些样本之间的一个很好的度量，并满足我们预先给定的限制条件。从这个意义上看，度量学习就是一种特定条件下的优化问题。*

*说到底，domain adaptation给人的感觉有点像在特征空间引入**某种力量**使得源域和目标域之间的分布距离能够更近一些。同样，metric learning也是如此。在人脸识别任务中，为了使得类间距离大于类内距离，一些研究引入了如contrastive loss，Large-margin Softmax Loss，Triplet Loss，CenterLoss等等损失函数（某种监督力量），调整向量间的空间分布。*

*为了使得源域和目标域在特征空间的距离更近（实现domain alignment），一些方法引入了基于metric learning的DA方法。*

###### [10.【给出了一种基于距离度量和相似性度量的损失减小域之间的差异】【Saeid Motiian】Unified Deep Supervised Domain Adaptation and Generalization](./10.【2017】【给出了一种基于线性距离度量和相似性度量的损失减小域之间的差异】【Saeid Motiian】Unified Deep Supervised Domain Adaptation and Generalization.md)

![image-20221006123330711](D:\markdown file\截图\image-20221006123330711.png)

![image-20221009152144570](D:\markdown file\截图\image-20221009152144570.png)

![image-20221009152305498](D:\markdown file\截图\image-20221009152305498.png)

![image-20221009152332113](D:\markdown file\截图\image-20221009152332113.png)

![image-20221009152347330](D:\markdown file\截图\image-20221009152347330.png)

> 需要注意的是这个**contrastive loss**，由L~SA~和L~s~两个loss组成，这个contrastive loss可以**拉近类内距离（semantic alignment）**的同时，**拉远类间距离（separation loss）**。

###### [11.【用MMD来拉近目标域与源域的数据分布】【Junlin Hu】Deep Transfer Metric Learning](./11.【2015】【用MMD来拉近目标域与源域的数据分布，用距离度量使类内距最小，类间距最大】【Junlin Hu】Deep Transfer Metric Learning.md)

![image-20221007135154819](D:\markdown file\截图\image-20221007135154819.png)

> 作者提出了一种Deep Transfer Metric Learning（DTML）方法，面向有监督或者半监督任务的transfer learning，其主要思路是使用**MMD损失缩小源域与目标域之间的距离**。值得注意的有一点，就是注意统计学上的MMD定义和实际中深度学习中用的MMD是有所不同的，及具体看[【MMD】MMD损失函数详解](./【MMD】MMD损失函数详解.md)

##### 3.2.1.3 基于attribute属性的方法

*上述多数方法利用softlabel或者metric learning的方式，实现**域对齐**和**语义对齐**。也有一些方法利用**类别属性对齐**实现**语义对齐**。*

###### [8.【采用DA的方法将softlabel用到细粒度图像分类中】【Timnit Gebru、Hoffman、Li Fei-Fei】Fine-grained Recognition in the Wild A Multi-Task Domain Adaptation Approach](./8.【2017】【采用DA的方法将softlabel用到细粒度图像分类中】【Timnit Gebru、Hoffman、Li Fei-Fei】Fine-grained Recognition in the WildA Multi-Task Domain Adaptation Approach.md)

![image-20220929131548340](D:\markdown file\截图\image-20220929131548340.png)

![image-20221009153948859](D:\markdown file\截图\image-20221009153948859.png)

![image-20221009154346918](D:\markdown file\截图\image-20221009154346918.png)

> 其主要原理是引入了多个损失函数来**监督/约束**模型训练，主要面向**无监督或者半监督**的域适应任务。具体的网络结构图如图所示。
>
> 从图中可以看出，网络是一个双分支的Siamese网络，分别接受源域和目标域的数据为输入，其分别输出若干分支输出，其中一个分支输出**细粒度类别**，其余输出**属性类别**（如外观是什么？颜色是什么？）
>
> 就**属性一致性损失**而言，说简单点，就是“**对齐**”网络输出的类别分布中**隐含的属性分布**与网络预测的**属性分布**。
>
> 这里就**属性一致性损失**展开来说，不妨以鸟的细粒度分类为例。为了获得网络输出的细粒度类别概率分布（下左上图）中**隐含的属性分布**（下右上图），比如我们要从鸟的细粒度分类任务中找到“外形大小=小”这个属性概率，我们只需要将所有拥有“外形大小=小”的类别（如蜂鸟等）对应的细粒度类别概率分布取平均即可（如下图左上到右上的过程）。
>
> 其训练的监督信息就是**网络在该属性上输出的概率分布（图右下）**。这个属性一致性损失由**对称的KL散度**构成（4）（5）。

##### 3.2.1.3 基于pseudo label伪标签的方法

*当对网络进行无监督微调时，可以用伪标签。*

###### [14.【提出WMMD损失解决了不同域同类别样本分布不均的问题，用到了伪标签】【Hongliang Yan】Mind the class weight bias Weighted maximum mean discrepancy for unsupervised domain adaptation](./14.【2017】【提出WMMD损失解决了不同域同类别样本分布不均的问题，用到了伪标签】【Hongliang Yan】Mind the class weight bias Weighted maximum mean discrepancy for unsupervised domain adaptation.md)

![image-20221011135204988](D:\markdown file\截图\image-20221011135204988.png)

> 图（a）是基于原始MMD方法的，因为存在**域间类别的权重偏差，**很明显效果一般。
>
> 图（b）是基于本文提出的加权MMD方法（WMMD）的，可以看到作者对源域中每个类别均赋予了一个**辅助权重（**红色数字），这个权重的引入使得源域的类别比例约等于目标域中的类别比例。接着，作者使用加权后的源域与目标域进行MMD，实现DA。
>
> 如何生成伪标签呢？就是简单的把目标域数据放入源域训练好的网络所生成的标签，叫做伪标签。
>
> 文章的重点其实并不在**伪标签**上，而是提出了一种加权MMD来弥补因**域间类别的权重偏差**而造成DA效果不佳的问题。

###### [15.【2017】【用伪标签和三分类器训练】【Kuniaki Saito】Asymmetric Tri-training for Unsupervised Domain Adaptation](./15.【2017】【用伪标签和三分类器训练】【Kuniaki Saito】Asymmetric Tri-training for Unsupervised Domain Adaptation.md)

![image-20221014122749672](D:\markdown file\截图\image-20221014122749672.png)

![image-20221014124823260](D:\markdown file\截图\image-20221014124823260.png)

> 为了实现无监督域适应（UDA），本文借鉴了**集成学习**的思路，提出了一种**非对称**的**三分支**网络。该网络的结构如图所示。
>
> 该网络由三个分支网络组成，这三个分支网络**共享**特征提取层（F），而后以不同的网络分支（ F1,F2,Ft ）引出不同的学习任务。
>
> 具体的**训练流程**如下：
>
> （1）先用源域数据来训练F+F1,F+F2 这两个网络。为了使得学习出来的F+F1,F+F2这两个网络能够**非对称**（内部参数尽量不同），作者希望分支 F1 的参数 W1 以及分支F2 的参数 W2具有较大差异，故在训练阶段引入W~1~^T^W~2~惩罚项进行训练。当W~1~和W~2~正交时，惩罚项去最小值，意思就是两个网络的参数越不同，惩罚项越小。目的就是使得学习出来的两个网络具有非对称性，因为只有非对称性的网络进行**集成学习**才比较好。
>
> （2）利用初步学习好的网络 F+F1,F+F2 ，输入目标域数据，获得在两个分支网络上各自的输出 y1,y2 。
>
> （3）为了获得**高置信度的伪标签** Tl （如果伪标签的置信度不高，会把模型带偏了），作者根据输出 y1,y2 设定了这样的判别规则，其中假设 C1,C2 为y1,y2的预测概率最大对应的类别：如果 C1=C2=C ，且 y1+y2>threshold 。也就是F+F1,F+F2这两个分支网络都判定该样本是类别C ，且判别概率之和大于设定阈值，那么该样本属于类别C的概率较大。
>
> （4）利用**高置信度的伪标签** Tl 来同时训练三个分支网络F+F1,F+F2,F+Ft。其中 F+F1,F+F2 两个网络使用源域数据 S +目标域伪标签数据Tl进行共同训练，训练目标为**上述公式**，而 F+Ft 网络则利用**分类损失**进行学习。

#### 3.2.2 统计准则（Statistic Criterion）

上面提到了Discrepancy-based方法的一个小类，即**基于class criterion的方法**。该类方法主要利用**标签信息**实现**知识迁移**，进而达到域适应的目的。当然了，上面提到的一些方法中也普遍引入了一些诸如MMD的损失函数，实现**域对齐**。

基于statistic criterion的方法，就如同其名字一样，表现为其在统计学的分布空间中利用一些统计学的方法求解**源域特征**与**目标域特征**之间的**转换关系**（transformation），进而实现**源域**和**目标域**的对齐。常见的对齐方法包含一些**衡量分布之间距离**的度量函数，诸如**MMD**，**CORAL**，**KL散度**以及**H散度**，等等。MMD我们在前面几篇文章中算是屡见不鲜了。

统计准则使用某些机制调整源域和目标域之间的统计分布偏移。最常用的方法是比较和减小distribution shift，例如：MMD（maximum mean discrepancy）、CORAL（correlation alignment）、KL散度、H散度等。

###### [16.【2014】【arXiv】【Eric Tzeng、Hoffman】【UC伯克利】【DDC，将MMD用在了倒数第二层】Deep Domain Confusion Maximizing for Domain Invariance](./16.【2014】【arXiv】【Eric Tzeng、Hoffman】【UC伯克利】【DDC，将MMD用在了倒数第二层】Deep Domain Confusion Maximizing for Domain Invariance.md)

###### [22.【2015】【arXiv】【Xu Zhang】【清华大学、哥伦比亚大学】【DTN，在第l-1层使用MMD损失，在最后一层产生伪标签来使用MMD损失】Deep Transfer Network Unsupervised Domain Adaptation](./22.【2015】【arXiv】【Xu Zhang】【清华大学、哥伦比亚大学】【DTN，在第l-1层使用MMD损失，在最后一层产生伪标签来使用MMD损失】Deep Transfer Network Unsupervised Domain Adaptation.md)

###### [24.【2016】【ECCV】【Baochen Sun】【波士顿大学】【引入Coral损失，比MMD简单效果还好】Deep CORAL Correlation Alignment for Deep Domain Adaptation](./24.【2016】【ECCV】【Baochen Sun】【波士顿大学】【引入Coral损失，比MMD简单效果还好】Deep CORAL Correlation Alignment for Deep Domain Adaptation.md)

#### 3.2.3 结构准则（Architecture Criterion）

旨在通过调整深度网络的体系结构来提高学习更多可迁移功能的能力。例如，自适应的BN、弱相关的权重和域指导的dropout等。

前面提到的一些方法往往建立在**权重共享**的双分支网络的基础上分别进行源域和目标域数据的特征提取。

这种共享权重的网络实际上可以看成一个单一的映射函数，这样就保证了源域特征与目标域特征处在相同的特征空间中，这样再采用一些enforcement，强迫两个域的分布较小，即可实现**域对齐**。域对齐会促使模型学习到**域不变特征**。

然而，一些方法认为如果双分支网络如果存在一些微小差异的话，并且这种差异的存在正好可以使得不同域的数据映射后，落到重叠的特征空间中。那么这样的话就无需一些诸如MMD的enforcement了。

因此，这些方法更侧重于对深度网络的设计与权重约束。作者将该类**侧重模型设计与权重约束的方法**统一命名为**基于Architecture criterion**的DA方法。

###### [26.【2016】【TPAMI】【Artem Rozantsev】【不使用权重共享，使用权重相关】Beyond Sharing Weights for Deep Domain Adaptation](./26.【2016】【TPAMI】【Artem Rozantsev】【不使用权重共享，使用权重相关】Beyond Sharing Weights for Deep Domain Adaptation.md)

### 3.3 基于对抗的DA方法（Adversarial-based）

#### 3.3.1 生成模型（Generative Models）

通常将基于生成对抗网络（GAN）的判别模型与生成成分相结合。 一种典型情况是使用源图像或噪声矢量来生成与目标样本相似的模拟样本，并保留源域的注释信息。

利用生成模型将带**标签的源域数据**转为对应的（生成的）**目标域数据**。这样生成的数据既保持了源域数据的标签，也将其**风格**转化为目标域。举个交通上的例子，我想做黑夜场景下的车辆检测，但是没有相应的标注数据怎么办？我们可以通过域迁移，将白天带标签的图片数据转为黑夜带标签的数据，这样就可以用生成的数据进行模型训练了。

**《Coupled Generative Adversarial Networks》**

>本文章提出了一个耦合的生成对抗网络（CoGAN），该网络由两个生成对抗网络 GAN1 和 GAN2 组成，如下图所示。
>
>GAN1 中的生成器以一个**噪声数据z**为输入，生成一张**源域图片** g1(z) ，其判别器 f1 用来判别生成的图片来自源域的概率； GAN2 中的生成器以**相同的噪声z**数据为输入，生成一张**目标域图片** g2(z) ，其判别器 f2 用来判别生成的图片来自目标域的概率。
>
><img src="D:\markdown file\截图\image-20221229144335662.png" alt="image-20221229144335662" style="zoom:50%;" />
>
>那这样可能会产生一个问题，也就是 GAN1 和 GAN2 生成的图片可能确实分别来自源域与目标域，但是二者的内容却完全不同。比如， GAN1 生成了一个数字“5”，而 GAN2 却生成了一个边缘字“6”，这两者虽然属于不同域（数字与边缘字），但是内容却完全不同。
>
>这怎么办呢？
>
>作者想到了一种方法，即“**共享权重**”。但是这个“共享权重”可不能随便“共享”，到底“共享”哪里的权重呢？是“low-level”的还是“high-level”的呢？是细节信息还是语义信息呢？作者提到：
>
>一般而言，相同（相似）的类别之间往往具有相同（相似）的语义信息，比如英短和美短之间就具有一些相似的特征，比如圆脸，短毛等等。
>
>作者认为如果共享那些用以获取“high-level”特征的网络权重，也许就能保证生成的图片处理不同的域，但保证相同的内容。
>
>这种“high-level”特征往往指的是那些低维度的特征，对**生成器**而言，就是**靠近输入的层**；对**判别器**而言，就是**靠近输出的层**。

**《Pixel-Level Domain Transfer》**

> 本文作者主要提出一个用于图片到图片转换任务的生成对抗网络，其结果如下图所示。该网络能够实现一张图片的域转换（比如风格转换），并且保持**语义属性**（semantic meaning）。
>
> ![image-20221229144449061](D:\markdown file\截图\image-20221229144449061.png)
>
> 所谓语义属性就是图片的**基本内容**，比如将真实风景图转为梵高风格的画，在保证风格变化的同时不缺失图中的基本信息（比如原图中有条河，在转换后的图片中也要保证相同的位置有条河）。
>
> 总的来说，生成的图片有两点要求：（1）足够真实，使得人难以分辨真假；（2）语义内容一致。
>
> - 就要求（1）而言，作者引入了一个**真假判别器**，该判别器接受真实图片和合成图片为输入（合成图片为生成器Converter C的输出）。其中真实图片的标签为1，合成图片标签为0，以此为监督信息对该**真假判别器**进行训练。训练**Converter C**的优化目标与**真假判别器**的优化目标正好相反，这将促使**Converter C**生成更真实（让真假判别器难以分辨）的合成图片。
> - 就要求（2）而言，作者分析了MSE作为衡量标准的缺陷，因为MSE要求非常严格的像素对齐，这会导致（1）生成的图片完全丧失多样性（2）生成的图片过于模糊。因此，作者就此提出了一个**域判别器**用来判断生成的图片与输入原图之间是否有关联。这个“**有关联**”建立在原图与其对应的标签图片上，而“**无关联**”建立在以下两种情况下，分别为（1）原图与生成图片无关联；（2）原图与真实的，非对应标签图片无关联。这样**域判别器**就可以学习到图片之间的关联性，利用对抗损失函数加以训练也将促使**Converter C**能够生成与输入图片关联的图片。
>
> 有了“**真假判别器**”和“**域判别器**”，生成器Converter C就能够生成真实的、关联的合成图片了。

###### [【2017】【CVPR】【Konstantinos Bousmalis】【谷歌】【训练一个模型来改变来自源域的图像，使其看起来像是来自目标域的采样，同时保持其原始内容】Unsupervised Pixel–Level Domain Adaptation with Generative Adversarial Networks](./泛读以及参考文献的文章.md)

#### 3.3.2 非生成模型（Non-Generative Models）

特征提取器不是使用输入图像分布来生成模型，而是使用源域中的标签来学习判别表示，并通过域混淆损失将目标数据映射到同一空间，从而得到域不变的表示。

引入判别器和对抗损失函数，判别器的目的是为了更好的区分源域与目标域的数据分布，对抗损失使得生成器将这两个域映射到难以区分的数据分布中（也就是domain confusion）

###### [9.【2015】【ICML】【Yaroslav Ganin】【DANN，将对抗性训练的思想使用到域适应中，梯度反转层】Unsupervised Domain Adaptation by Backpropagation](./9.【2015】【ICML】【Yaroslav Ganin】【DANN，将对抗性训练的思想使用到域适应中，梯度反转层】Unsupervised Domain Adaptation by Backpropagation.md)

###### [25.【2017】【CVPR】【Eric Tzeng、Judy Hoffman】【UC伯克利、斯坦福大学】【对抗DA方法中loss最好用GAN的，权重最好不要共享】Adversarial Discriminative Domain Adaptation](./25.【2017】【CVPR】【Eric Tzeng、Judy Hoffman】【UC伯克利、斯坦福大学】【对抗DA方法中loss最好用GAN的，权重最好不要共享】Adversarial Discriminative Domain Adaptation.md)

### 3.4 基于重构的DA方法（Reconstruction-based）

#### 3.4.1 编码器解码器重构（Encoder-Decoder Reconstruction）

使用堆叠式自动编码器（SAEs）

###### [【2016】【NIPS】【Konstantinos Bousmalis】【谷歌】【利用重构的方法提取不同域之间的公有特征】Domain Separation Networks](C:\Users\Emoaya\Desktop\文章\泛读文章\泛读以及参考文献的文章.md)

###### [【2016】【ECCV】【Muhammad Ghifary】【惠灵顿维多利亚大学】【DRCN，用重构的方法但是不严谨】Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation](C:\Users\Emoaya\Desktop\文章\泛读文章\泛读以及参考文献的文章.md)

#### 3.4.2 对抗重构（Adversarial Reconstruction）

重建误差（reconstruction error）是通过GAN鉴别器获得的循环映射（cyclic mapping），测量为每个图像域内的重建图像和原始图像之间的差异









