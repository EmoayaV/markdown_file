## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\34.【2018】【CVPR】【Zhirong Wu】【UC伯克利、香港中文大学】【提出个体判别任务InstDisc，引入一种新的无监督分类任务的方法】Unsupervised Feature Learning via Non-Parametric Instance Discrimination.pdf)

### 1.1 在干什么、有什么贡献、什么结论

本文的方法主要是用于**无监督的图像分类任务。**

文章假设：我们能通过训练基于实例（将每一个样本视为单独的类别）的分类器代替基于类别的分类器，得到可以捕捉视觉相似性的特征表达。我们将其总结为**非参数化实例级判别**，并且通过**噪声对比估计（noise-contrastive estimation）**解决大量实例类别引起的计算困难。

<img src="D:\markdown file\截图\image-20230103163555607.png" alt="image-20230103163555607" style="zoom:50%;" />

**文章收到了有监督学习的启发，如上图所示，如果把一张豹子的图片喂给一个有监督学习训练好的模型，我们会发现它给出的分类结果排名前几的全是和豹子相关的，比如猎豹、雪豹等，从图片来看，这些排名靠前的物体长得都是非常相似的，排名靠后的往往都是和豹子无关的类别。这些类别排名靠前的原因并不是他们有相似的语义标签，而是因为照片本身长得太像了，作者基于这个观察提出了个体判别的任务。**

**贡献**：**InstDisc是对比学习的开山之作，提出了个体判别任务。**

## 2. 网络结构

![image-20221122151417877](D:\markdown file\截图\image-20221122151417877.png)

<img src="D:\markdown file\截图\image-20221122155142061.png" alt="image-20221122155142061" style="zoom:50%;" />

这个网络非常简单，首先f是CNN网络，用于提取特征，在经过L2正则化和非参的softmax分类器，得到基于实例的概率。训练目标即最小化负对数似然概率，如公式(3)。

测试：首先将测试样本经过上述网络变成一个特征向量，然后分别与储存器中的向量vi计算余弦相似度，找出最相似的几个实例。

**用一句话总结这个网络：就是用CNN网络把所有的图片都编码成一个特征，希望这些特征在最后的特征空间里能尽可能的分开。如何去训练CNN网络呢？就使用对比学习的方法，需要有正负样本，根据个体判别任务，正样本就是图片本身，负样本是就是数据集中的其他图片，如果做对比学习，那么大量的负样本存在哪里呢？作者就用了memory bank的形式进行存储。**

**训练简单来说batchsize 大小就是正样本个数，负样本从memory bank里面随机抽取（本文抽4096个 负样本/batch），训练一个batch后，把从memory bank 抽出的样本进行更新。loss选取的是NCEloss。**

## 3. 具体细节

**储存器(memory bank)：**

储存器是储存无标签样本特征的空间，V={v1, v2, ..., vn}，其中每个vi都是通过一个实例得到的特征向量。

**参数化的softmax分类器：**

<img src="D:\markdown file\截图\image-20221122153300704.png" alt="image-20221122153300704" style="zoom:50%;" />

**非参数化的softmax分类器：**

<img src="D:\markdown file\截图\image-20221122153321161.png" alt="image-20221122153321161" style="zoom:50%;" />

可以看到参数化的sotfmax分类器和非参数化的softmax分类器最大的区别就是wi和vi的区别，w是通过有标签的样本训练训练的来，所以wi可以看作一个类别的原型(a class prototype)，而vi是无标签样本经过特征提取器(CNN网络)后得到的特征。

从wi到vi的变化是显著的，原softmax公式中的权值向量wi仅对已知类有效，因此，它们没有泛化到新类别的能力，当我们去掉这些权重向量wi时，我们的学习目标完全集中在特征表示及其度量上，它可以应用于空间的任何地方，并在测试时应用于任何新的实例。

**减少参数：**

我们使用noise-contrastive estimation (NCE)近似接近softmax，从而减少参数。

## 创新点

这篇文章最大的创新点就是引入一种新的无监督分类任务的方法。
