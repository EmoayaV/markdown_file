## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\9.【2015】【ICML】【Yaroslav Ganin】【DANN，将对抗性训练的思想使用到域适应中，梯度反转层】Unsupervised Domain Adaptation by Backpropagation.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**背景：目标域无监督**

**本文是第一篇将对抗性训练的思想使用到域适应中的论文。**

我们提出了一种域适应的新方法，该方法可以使用来自**源域的大量标记数据**和来自**目标域的大量未标记数据**(不需要标记目标域数据)进行训练。

**目标：**目标域的样本作为输入可以预测出正确的标签。

## 2. 模型介绍

### 2.1 模型初始设置

源域是有标签的数据集，目标域是无监督的数据集，事先知道样本是来自源域还是目标域，来自源域的第i个样本域标签（domain label）为 d~i~ = 0，来自目标域的第j个样本域标签（domain label）为 d~j~ = 1。我们的目标是对于目标域无标签数据的输入，我们可以正确预测其类别。

### 2.2 前馈网络结构

![image-20221024163958767](D:\markdown file\截图\image-20221024163958767.png)

![image-20221017163110123](D:\markdown file\截图\image-20221017163110123.png)

**DANN与GAN的区别：**

**GAN的更新过程：**对于GAN来说，更新生成器（这里叫做特征提取器）和判别器是迭代进行，怎么做呢，首先构建两个网络，分别是上图绿色的特征提取器网络（G网络）和红色的域判别器网络（D网络）。假设源域x，标签1，目标域z，标签0，那么更新生成器网络（G网络）把源域1作为标签，目标域图片经过判别器的结果d(g(z))，则损失为gloss = -1/N Σ~N~log(d(g(z))。更新判别器网络（D网络）把源域1作为真标签，把目标域0作为假标签，源域图片经过判别器的结果d(x)，目标域图片经过判别器的结果d(g(z))，则损失为dloss = -1/2N Σ~N~（log(d(x))+log(1-d(g(z))）。

**DANN做的改进：**但是这样迭代更新要反向传播两次，有没有数目办法只传播一次就可以更新全部参数呢？首先可以看到更新生成器和判别器的反向传播过程是重复的（黑色圈），换个角度想，其实更新生成器就是为了使判别器损失增大，更新判别器就是为了使判别器损失减小，那么干脆大家都用判别器的损失不用生成器的损失就好了，只用在反向传播时判别器部分的梯度取正，生成器部分的梯度取负就行了。虽然作者想法很好，但是存在两个问题，第一个问题是pytorch框架中的backward方法用的是对根节点到叶子节点用链导法则进行求导，没有梯度反转的操作，所以需要手动实现。

![image-20221001155528418](D:\markdown file\截图\image-20221001155528418.png)

![image-20220831123100392](D:\markdown file\截图\image-20220831123100392.png)

> 作者提出的模型架构中包括一个**特征提取器**（图中的绿色部分）以及一个**深度标签预测器**（图中蓝色部分），二者结合构成了一个标准的**前馈架构**。
> 而该模型为了解决无监督域适应问题还添加了一个**域分类器**，并将一个**梯度反转层**插入到在特征提取器与域分类器之间。该梯度反转层在反向传播的训练期间，将梯度乘以某个负常数。而模型在正常的前向训标准练中，最小化标签预测损失(对于源域的样本)和域分类损失(对于所有样本)。梯度反转确保两个域上的特征分布是相似的(对于域分类器来说是尽可能不可区分的)，从而产生域不变的特征。

**前馈网络结构：**首先把样本x放入特征提取器G~f~（a feature extractor），这部分网络参数是θ~f~，所以这个过程记作 G~f~(x; θ~f~)。再把经过特征提取器的特征放入标签预测器G~y~（label predictor），这部分网络参数是θ~y~，所以这个过程记作 G~y~(x; θ~y~)。最后把经过特征提取器的特征放入域分类器G~d~（domain classifier），这部分网络参数是θ~d~，所以这个过程记作 G~d~(x; θ~d~)。

### 2.3 训练过程

**训练：**首先用源域的数据训练特征提取器和标签预测器。然后再固定域分类器的参数θ~d~和标签预测器的参数θ~y~，最大化域分类器的损失来优化特征提取器的参数θ~f~。最后再固定特征提取器的参数θ~f~和标签预测器的参数θ~y~，最小化域分类器的损失来优化域分类器的参数θ~d~。

### 2.4 损失函数

![image-20221003142755348](D:\markdown file\截图\image-20221003142755348.png)

![image-20221003124510449](D:\markdown file\截图\image-20221003124510449.png)

**损失函数：**上述的训练可以用一个损失函数（1）表示，红框是用源域的数据，先放入特征提取器G~f~再放入标签预测器G~y~，最后再和标签做损失的结果，注意这个标签是类别标签。蓝框是用源域和目标域的数据，先放入特征提取器G~f~再放入域分类器G~d~，最后再和标签做损失的结果，注意这个损失是域标签。红框的作用是使类别分类准确，蓝框的作用是特征对齐。

**训练过程：**（2）固定θ~d~更新θ~f~和θ~y~，这时对于红框的损失我们希望**越小越好**，对于蓝框的损失我们相当于在训练生成器，如果没有负号我们希望损失越大越好，因为损失大证明分不开两个域，生成器的性能更好，有了负号我们就希望损失**越小越好**。（3）固定θ~f~和θ~y~更新θ~d~，这时对于红框的损失不参与更新参数的过程，可以看作常数，对于蓝框的损失我们相当在训练判别器，如果没有负号我们希望损失**越小越好**，因为损失小证明判别器分得开两个域，判别器性能更好，有了负号我们就希望损失越大越好。

## 3.梯度反转层

### 3.1 为什么（4）-（6）不能用传统的SGD呢？

![image-20221006141902762](D:\markdown file\截图\image-20221006141902762.png)

![image-20221006141723706](D:\markdown file\截图\image-20221006141723706.png)

因为pytorch中的backward方法用的是对根节点到叶子节点用链导法则进行求导，只能提取出叶子节点的梯度。比如上图的红线，虽然作者把参数更新分为∂L~y~/∂θ~y~和∂L~y~/∂θ~f~，但是在实际中这两部分在一条链上，是同时进行的，所以说这两部分的偏导符号是相同的。再看看蓝线部分，作者把参数更新分为∂L~d~/∂θ~d~和-λ∂L~d~/∂θ~f~，偏导符号是不相同的，所以用pytorch中的backward方法是没法实现的。

### 3.2 梯度反转层的详解

![image-20221006154721354](D:\markdown file\截图\image-20221006154721354.png)

**GRL作用：**将传入到GRL的梯度乘上一个负数，使得在GRL前后的网络的训练目标是相反的。如果不用梯度反转，用Gan那种训练方法其实效果也不差，这个主要是想实现端到端的训练。

**对抗的话，损失函数加个符号不就行了？**

loss加符号的话对抗需要forward两次，一次训练判别器减小loss，一次训练生成器增大loss；但是梯度反转的话可以在一次forward之后，反转生成器的梯度就达到了对抗的效果；但后者的话在一次forward判别器和生成器都会更新，但是一般Gan的话通常是判别器多更新几次，所以Gan一般是用前者。

**为什么要GRL？**

这个模型有三部分：

绿色（后文用G指代）：特征提取，得到的feature是共享的

蓝色（后文用B指代）：对源域进行训练，原论文是处理分类任务，所以这部分就是分类误差

紫色（后文用P指代）：二分类器，标签是 源域 or 目标域

B的目标是最小化分类误差（或者任何其他你的目标问题的loss），但是很明显B会对源域overfitting；P的目标是最小化二分类误差，也就是尽可能区分两个域。

然后关键就是G了，它要提取一个供B和P共享的feature，这个feature有两个目标：最小化目标loss（帮助B）；最大化二分类误差（对抗P）。其中第二个目标就是用GRL实现的。

**一些细节：**

![image-20221003145808591](D:\markdown file\截图\image-20221003145808591.png)

![image-20221003160039514](D:\markdown file\截图\image-20221003160039514.png)

![image-20221003144628232](D:\markdown file\截图\image-20221003144628232.png)
