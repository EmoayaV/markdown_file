## 前言

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章_时序\1.【2019】【DMKD】【Hassan Ismail Fawaz】【时序综述】Deep learning for time series classification a review.pdf)

[知乎解读](https://zhuanlan.zhihu.com/p/435697318)

[CSDN解读](https://blog.csdn.net/weixin_40818267/article/details/102616515)

1.时序回归和时序分类的问题形式其实非常相似，时序分类的方法可以直接套用过来

2.回归和forecasting中的单步预测的问题形式非常相似，很多时候可以互相转换

3.时序问题和nlp问题的范式是非常相似的，nlp任务和时序任 务的nn的结构设计上几乎是一样的，例如文本分类对标时序分类，文本回归对标时序回归，而第四点提到的时序中三大任务的nn结构是可以很轻松的互相套用的，因此，nlp中的许多模型结构设计也可以经过简单的改造适配到时序问题中，比如越来越多的transformer被塞进来解决时间序列问题。

## 1. 摘要abs和导言intro

### 1.1 在干什么、有什么贡献、什么结论

综述。

## 2. 组件

### 2.1 深度时序分类模型的基本结构

![image-20230404112053150](D:\markdown file\截图\image-20230404112053150.png)

>时序分类任务的流程图

### 2.2 本文着重介绍的用于TSC任务的主流神经网络模型（2018年前）

用于TSC任务的主流神经网络模型，即特征提取器部分。（注意这是2018年以前的）

虽然这篇综述主要介绍了三种主要的神经网络架构：多层感知机MLP，卷积神经网络CNN，回声状态网络ESN。**注意：Transformer发表于2017，BERT发表于2018，也就是说当时注意力机制还没有应用到时序分类任务上！**

#### 2.2.1 多层感知机MLP

缺点：没有位置信息（也就是空间不变性）。**现在一般通过位置编码解决这种空间信息缺失问题。**

#### 2.2.2 卷积神经网络CNN

![image-20230404154437451](D:\markdown file\截图\image-20230404154437451.png)

>卷积神经网络在时序分类中的应用

优点：通过卷积核强行引入位置信息，每个卷积核学习一种特征。

缺点：目前看来比较落后，因为CV的不少任务都开始借助NLP的方法，时序预测本来就是一种类似于NLP的数据，所以直接上NLP的方法就行了。

#### 2.2.3 回声状态网络ESN（可以看作RNN加强版）

RNN除了时间序列预测外，我们发现这些神经网络很少用于时间序列分类，这主要是由于以下三个因素：①梯度消失问题②不适合做分类③RNN是串行训练，没有并行，很难训练。

## 3. 基于深度的时间序列分类算法划分

![image-20230404155850014](D:\markdown file\截图\image-20230404155850014.png)

>用于TSC的深度学习方法可以分为两大类:生成模型和判别模型，注意这里没有出现Transformer

时间序列分类中的深度模型应用大体上可以划分为两类，**一类是生成式深度模型，一类是判别式深度模型**

