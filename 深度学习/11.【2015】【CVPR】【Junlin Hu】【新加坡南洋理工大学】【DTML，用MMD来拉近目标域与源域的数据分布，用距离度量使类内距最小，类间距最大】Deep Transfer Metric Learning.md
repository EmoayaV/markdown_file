## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\11.【2015】【CVPR】【Junlin Hu】【新加坡南洋理工大学】【DTML，用MMD来拉近目标域与源域的数据分布，用距离度量使类内距最小，类间距最大】Deep Transfer Metric Learning.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**问题研究背景**：目标域无监督

**重点可以看看这篇文章用MMD来拉近目标域与源域的数据分布，而前面的文章主要用一个对抗过程来拉近。**

## 2. 损失函数和方法

一个好的距离应该反映出原始样本中的距离远近的信息。我们现在有的信息是什么？我们仅仅有两个domain的数据，其中一个domain没有label。在这里，为了衡量这些样本之间彼此的相似性，作者借鉴了流行的线性判别分析的方法，在深度网络中计算样本的**类内距离和类间距离**，目标就是要使得**类内距最小，类间距最大**。这用公示表示就是：

<img src="D:\markdown file\截图\image-20221007124630359.png" alt="image-20221007124630359" style="zoom:50%;" />

其中 S~c~^(M)^ 表示类内距， S~b~^(M)^ 表示类间距，α是平衡因子来平衡类内距和类间距的重要性。 M 表示网络的最后一层， m 表示网络的第 m 层。 γ 是平衡因子，这一项是正则化项，和普通的深度学习一样。

如何计算类内和类间距离？这里引入了简单的 k 均值计算方法，*k*反映了相似度。如果样本 x~i~ 在样本 x~j~ 的 k1个类内邻居里，就把P~ij~ 置为1，我们就认为它们相似，就属于一个类。反之，则不是同类，就把P~ij~ 置为0。如果样本 x~i~ 在样本 x~j~ 的 k2个类间邻居里，就把Q~ij~ 置为1，我们就认为它们相似，就属于一个类。反之，则不是同类，就把Q~ij~ 置为0。因此，类内和类间距计算方法为：

<img src="D:\markdown file\截图\image-20221007131855365.png" alt="image-20221007131855365" style="zoom:50%;" />

注意到这里对于类内和类内距，定义了不同的 k 来反映相似度。 d~f(m)~^2^ 是一个距离度量函数，如下：

<img src="D:\markdown file\截图\image-20221007135040783.png" alt="image-20221007135040783" style="zoom:50%;" />

上面的条件并没有考虑到在迁移学习中的学习问题。因此，为了**减小源域和目标域的分布差异**，作者将迁移学习中常用的**MMD**度量引入：

<img src="D:\markdown file\截图\image-20221007135154819.png" alt="image-20221007135154819" style="zoom:50%;" />

综合上面的度量学习，整体优化目标变成：

<img src="D:\markdown file\截图\image-20221007135214553.png" alt="image-20221007135214553" style="zoom:50%;" />

这个式子很好理解。可以通过梯度下降很好地进行优化。但是这样就完了吗？我们还有什么信息没有利用？我们还遗漏了重要的信息：目前我们只使用了最后M层的输出特征，没有用到前M-1个隐藏层输出的特征。作者又进一步提出：我们不应该只考虑一层的信息，而是将每一层的特征都考虑进来。因此，最后的优化目标为：

<img src="D:\markdown file\截图\image-20221007140401312.png" alt="image-20221007140401312" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221007140632306.png" alt="image-20221007140632306" style="zoom:50%;" />

其中 h(x) = max(x, 0)， *τ* ^(m)^ 是正的阈值，控制隐藏层每一层的损失所占的比重，如果阈值大那么这一层的损失会变为0，*ω*^(m)^ 也是控制隐藏层每一层的损失所占的比重。



## 3. 具体算法流程

<img src="D:\markdown file\截图\image-20221007135636274.png" alt="image-20221007135636274" style="zoom:50%;" />
