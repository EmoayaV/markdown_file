## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\28.【2020】【ICML】【Yadan Luo】【OSDA，提出PGL方法，使用GNN网络完成DA任务，将有伪标签的目标数据加到源数据迭代训练】Progressive Graph Learning for Open-Set Domain Adaptation.pdf)

### 1.1 在干什么、有什么贡献、什么结论

提出了**渐进式图学习 Progressive Graph Learning (PGL)** 的框架。

提出了OSDA问题的4个准则：

1.要训练两个分类器，一个分类器把目标域样本分为已知类和未知类，一个分类器在共享类别上完成分类任务。

2.将分类置信度低的目标域样本从目标域逐渐剔除，作为标签为'未知'的类别加入源域的训练。

3.解决条件偏移 (conditional shift) 的问题，具体来说 (1) 我们设计了一种情景训练方案，并通过在每个情景中逐步用伪标记的目标域样本替换源样本，逐步更新训练集，使条件分布跨域对齐。(2) 在原始分类网络上又加入GNN网络。

4.解决域偏移 (domain shift) 的问题，主要用对抗过程。

## 2. 网络结构

<img src="D:\markdown file\截图\image-20221113161859017.png" alt="image-20221113161859017" style="zoom:50%;" />

在一个batch中的所有样本都可以构成一个无向图，每个顶点vi∈V都与一个源特征或一个目标特征相关联，节点vi和vj之间的边eij∈E度量节点间的相关性。 

**Step1：初始化网络**

边的更新：

<img src="D:\markdown file\截图\image-20221113161545384.png" alt="image-20221113161545384" style="zoom:50%;" />

节点更新：

<img src="D:\markdown file\截图\image-20221113161605980.png" alt="image-20221113161605980" style="zoom:50%;" />

可以看见图中主要有三个损失，分别是边损失、节点损失和对抗损失。

对抗损失：

<img src="D:\markdown file\截图\image-20221113162217591.png" alt="image-20221113162217591" style="zoom:50%;" />

节点损失：

<img src="D:\markdown file\截图\image-20221113162346305.png" alt="image-20221113162346305" style="zoom:50%;" />

边损失：

<img src="D:\markdown file\截图\image-20221113162410322.png" alt="image-20221113162410322" style="zoom:50%;" />

最终损失：

<img src="D:\markdown file\截图\image-20221113162441235.png" alt="image-20221113162441235" style="zoom:50%;" />

具体细节先不讨论。

**Step2：给目标域的样本打上伪标签**

<img src="D:\markdown file\截图\image-20221113162956267.png" alt="image-20221113162956267" style="zoom:50%;" />

利用Step1得到的最优模型参数，冻结模型，并将所有目标样本向前输入，得到每个类别的概率，把容易分的目标域样本放入已知类别，把不容易分的目标域样本放入未知类别。

**Step3：把带有伪标签的目标域样本与源域样本混合**

在Step2后，我们将源数据与带有伪标签的目标域样本与源域样本混合，再次训练，一直循环。

## 创新点

1.使用GNN来做DA任务，比较玄学。

2.给目标域的样本打上伪标签，再把带有伪标签的目标域样本与源域样本混合进行训练，以此解决条件偏移的问题，或者说完成源域和目标域相应类别下的特征对齐的目的，这种伪标签的训练方式可以注意一下。

下面这篇文章也用到了伪标签：

[15.【2017】【ICML】【Kuniaki Saito】【用伪标签和三分类器训练】Asymmetric Tri-training for Unsupervised Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\15.【2017】【ICML】【Kuniaki Saito】【用伪标签和三分类器训练】Asymmetric Tri-training for Unsupervised Domain Adaptation.pdf)

==**实际上伪标签的使用大概就是两个步骤**==

==1.先把目标域无标签的样本根据某个度量(比如置信度)打上伪标签==

==2.把带伪标签的数据集和源域数据集混合，放入网络再次训练==

