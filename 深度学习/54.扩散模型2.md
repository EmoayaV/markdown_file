## [视频链接](https://www.bilibili.com/video/BV1bd4y1x7gw/?vd_source=320c7991448cfd9ab61c95f538663e07)

## [知乎解析](https://zhuanlan.zhihu.com/p/572770333)

![image-20230224094400929](D:\markdown file\截图\image-20230224094400929.png)

![image-20230227085756725](D:\markdown file\截图\image-20230227085756725.png)

前向过程，从图片生成噪声，从噪声生成图像可以看作一个去噪的过程，想学习如何去噪，那么从直觉上来讲就要学习如何生成噪声，这就是扩散模型的第一步，加噪，这个加噪声的过程是分好多步的，不是一次完成，是从x0到xN的过程，原始论文中N=2000。

![image-20230228084922858](D:\markdown file\截图\image-20230228084922858.png)

β是一个权重项，随着t的增大增大，α相反，随着t增大减小。

xt和她上一时刻最相关，就是xt-1。红色五角星公式是从上一时刻xt-1加噪生成下一时刻xt的公式，根号αt相当于上一时刻xt-1的权重项，根号1-αt相当于噪声z1的权重，那么β随着t增大增大，那么根号αt随着t增大减小，根号1-αt随着t增大增大。就是说随着t的增加，噪声对于生成的图像影响越来越大，上一时刻的图像对于这一时刻图像生成越来越小。

![image-20230228090031199](D:\markdown file\截图\image-20230228090031199.png)

![image-20230228090701236](D:\markdown file\截图\image-20230228090701236.png)

扩散模型不像RNN是串行计算，扩散模型可以通过x0直接求出任意时刻xt的输出，因为α0到αt都是已知的，所以如果生成从t=0到t=100的加噪图像，可以并行计算生成，最后的加噪公式是红色菱形公式。（zt_hat不是累乘，就是一个标准正正态分布）

![image-20230228091135453](D:\markdown file\截图\image-20230228091135453.png)

![image-20230228091719015](D:\markdown file\截图\image-20230228091719015.png)

光加噪是不够的，还需要反向过程来去噪生成图像。去噪不像加噪的过程，加噪可以从x0推出最后时刻xt的图像，而去噪过程不能从xT求出x0的图像。虽然不能直接从xT还原出x0的图像，但是可以从xT还原出xT-1的图像。

![image-20230228095956535](D:\markdown file\截图\image-20230228095956535.png)

![image-20230228100730790](D:\markdown file\截图\image-20230228100730790.png)

![image-20230228100856956](D:\markdown file\截图\image-20230228100856956.png)

![image-20230228111226620](D:\markdown file\截图\image-20230228111226620.png)

![image-20230228152208209](D:\markdown file\截图\image-20230228152208209.png)

要求已知xt的情况下xt-1的分布（也就是求期望和方差），用贝叶斯公式转换为已知xt-1的情况下，xt的分布，方便计算。

多个正态分布相乘除其乘积的分布不再是正态分布，但是正比于正态分布。我们将其（已知xt的情况下xt-1的分布）化简，可以通过公式的到他的期望和方差，方差是个常数，而期望和x0、xt有关，问题就是我们只知道xt，不知道x0。但是xt可以由x0计算得到，所以x0可以由xt表示。最终分布（已知xt的情况下xt-1的分布）的期望只包含标准正态分布zt和前一时刻的输入xt。

但是这么算有个问题，我们不知道zt是什么。我们是无法直接求出zt的，但是我们可以求个近似解，近似解怎么求呢，可以通过神经网络猜一个近似解。如果通过神经网络训练那么我们需要知道预测值和标签值，预测值是我们通过神经网络猜的，标签值就是我们前向过程从xt-1到xt所加的噪声。那么这个噪声就是咱们前向过程时加的噪声，这个噪声是已知的，所以说前向过程也可以看作是一个加标签的过程。

![image-20230228154538268](D:\markdown file\截图\image-20230228154538268.png)

![image-20230228163106936](D:\markdown file\截图\image-20230228163106936.png)

训练阶段

第一步，x0表示一个数据集，数据集中的图像都服从与一个分布q(x0)，比如都是猫的图片。

第二步，构建一个t的序列服从于均匀分布，对于一个batch中的图像，每个图像随机扩散t步，比如说对于batch中的第一张图像，扩散30步，第二张图像扩散150步，扩散几步都是随机值。

第三步，构建服从于标准正态分布的噪声。

第四步，梯度下降，θ是要学习的参数，ε是生成xt所用到的噪声，εθ是模型，模型有两个输入，分别是根号αtxo-根号1-αtε表示前向过程生成的xt，还有一个是t表示扩散了多少步（这里可以理解为transformer中位置编码引入的位置信息），εθ(....)表示输出。

测试阶段（也就是sampling阶段，由加噪后的图像xT生成原始图像x0）

思想是一步一步来，想从xT生成x0不可能一步做成，先从xT生成xT-1，..，最后再由x1生成x0。

重点是第4行公式，我们求的是什么？求的是已知xt的情况下xt-1的分布，求分布主要求什么？求的是期望和方差，只要知道期望和方差就可以从标准正态分布，构造出一个满足期望方差的分布。

看第四行公式，前面一项加后面一项，后面一项z是服从标准正态分布的随机变量，由于方差是固定的，不含参的，所以我们可以直接求出，在随机变量前乘一个方差项构造出xt-1的方差。接下来我们需要构造期望，前面一项都是函数、常数，不是随机变量，所以前面一项主要影响期望，期望的公式我们上面推到过，和xt、z有关，所以我们直接带入。这样就得了最终的xt-1的分布。迭代，最后得到x0.