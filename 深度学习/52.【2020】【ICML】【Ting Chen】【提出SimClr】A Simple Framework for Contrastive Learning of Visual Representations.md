## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\52.【2020】【ICML】【Ting Chen】【提出SimClr】A Simple Framework for Contrastive Learning of Visual Representations.pdf)

### 1.1 在干什么、有什么贡献、什么结论

对比学习。

## 2.具体细节

<img src="D:\markdown file\截图\image-20230108145734523.png" alt="image-20230108145734523" style="zoom:50%;" />

如果有一个minibatch的图片，假如说是x，那么就对minibatch的所有图片做不同的数据增强，就会得到xi和xj，那么同一个图片延伸得到的两个图片呢，就是正样本，如果你的batchsize是n的话，那么你的正样本个数就是n，那么负样本个数呢就是这个batchsize剩下的所有样本，以及他们经过数据增强后的样本，就和我们invaspread方法里讲的一样，是2(n-1)，有了正样本之后就要对其进行编码，所以说通过一个编码器f，这两个f呢是共享权重的，也就是说只有一个编码器，simclr一个重大的创新点就是在这个h特征之后，又加了一个叫做projector的东西，也就是这里的g，这个g呢说白了十分简单，就是一个mlp层，就是说只有一个全连接层，后面跟一个relu的激活函数，但是就是这么简简单单的一层mlp，能让最后学到的特征，在imagenet这个分类任务上呢，直接提升10个百分点，这个效果是在别的任何的任务里，或者说在有监督学习里面呢，是很难遇到的，很少有说加一个mlp就可以提升这么多，所以说这是一个非常有趣且惊讶的结果，但是在这个simclr框架里呢，可以想象成我有一个特征之后我在做一个非线性变化，就得到了另外一个特征，也就是说最后去做对比学习的那个特征，一般这个特征z呢，他的维度就会小一点，本文用了128维度，最后就衡量一下正样本直接能不能达到相似、一致，他们采用的是一个叫做normalized temperature scaled的交叉熵函数，normalized就是说在z特征后面进行了L2归一化，temperature scale就是说在这个loss里乘了个tao，所以说这个loss和之前说的infoNCE loss呢，是非常接近的，这里还要强调一个点，就是这个projection head了，这个g函数只有在训练的时候使用，而在做下游任务时，就把projection head 的g函数丢掉了，还是只用特征h去做下游任务的，这样的话和之前的工作也可以公平的对比，并没有多加一层，加上这个g函数只是为了王模型训练的更好。

和moco比起来这里只用了一个编码器，不需要队列也不需要动量编码器，正负样本全部是从一个minibatch中得来的，整个前向过程非常直接，就是图片进入编码器编码，让后projector进行降维，最后算个对比学习loss就行了。之前说过之前19年CVPR的工作incaspread可以看作simclr的前身，为什么这么说呢，其实invaspread整体的思路和结构和simclr基本一致，二者的区别呢其实都在simclr摘要的贡献列表里了，首先第一，simclr用了更多的数据增强，他们发现对比学习是需要很强的数据增强的技术的，第二，simclr加了一个projector，也就是g函数，就是一个mlp层，第三，他们用了更大的batchsize，训练时间更久，

<img src="D:\markdown file\截图\image-20230108160916038.png" alt="image-20230108160916038" style="zoom:50%;" />

为了让读者知道哪些数据增强有用，哪些没用作者还对7种数据增强做了详细的消融实验，结论是最有效的数据增强是crop和color，就是随机剪裁和随机色彩变幻。

<img src="D:\markdown file\截图\image-20230108162640803.png" alt="image-20230108162640803" style="zoom:50%;" />

图中的non-linear，就是全连接+激活函数，linear是只要全连接层，none就是不要加一层，不要这个g函数，像invaspread、moco一样，编码器出来的特征直接去做对比学习。

还有一点是simclr提出的在最后一层加一个mlp，如果h是一个res50提出的特征h，2048维度，z就是经过projector后的维度，一般是128维。

我们会发现两个很有意思的现象，第一个是如果用non-linear的方式像比于什么都不用的none方式，结果要提升10几个点，第二个是经过non-linear后，特征z无论是32、64、128、256、512、1024还是2048，其实都没他打区别，这也就是为什么现在对比学习都选一个比较低的特征，因为128维度就够了，再高再低结果也没有太大的变化，至于为什么加一个non-linear就提升这么多呢，至今也没有什么解释。