## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\6.【2015】【ICCV】【Eric Tzeng、Hoffman】【UC伯克利】【用对抗对齐特征用软标签对齐类别】Simultaneous Deep Transfer Across Domains and Tasks.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**背景：半监督和监督**

![image-20220923140401327](D:\markdown file\截图\image-20220923140401327.png)

现有的迁移学习方法很多都只做了一步：域适应，也就是减少边缘概率(marginal distribution)差异----使两个域尽可能重叠、融合，**但是当边缘分布得到对齐之后，并不能保证每个域之间的类别能够对齐，**类别没有对齐有什么影响呢？论文中并没有很好的说明，那就根据我的理解强行解释一波，比如分类器对源域中的一张图片识别出是一个瓶子的概率最大，是一个马克杯的概率次之，在目标域中有瓶子和玻璃杯这两个类别，但是没有马克杯这个类别怎么办，不好用源域辅助目标域判别了呀。同时，在目标域中识别出瓶子的概率最高（与源域一样），识别是玻璃瓶的概率次高（与源域中马克杯类似），那么通过类别对齐，我们想让源域中马克杯这个类别近似看做是目标域中的玻璃杯，并且将瓶子–马克杯这两个源域之间的类别关系（识别出瓶子概率最高，马克杯次之）也映射到目标域中的瓶子–玻璃杯中。另外，网络学习的目的之一是将数据与标签（类别）完成一种映射，在迁移学习中，我们希望能够通过源域与目标域尽可能的相似（域适应），然后通过源域和目标域完成与标签的映射，因为用到的绝大部分数据是来自源域的，但是目标域中标签之间的关系并不一定和源域的相似，就像域适应一样—源域和目标域数据之间并不一定相似，**域适应通过边缘对齐让源域和目标域之间的数据尽可能相似，而任务迁移则可以通过类别对齐，将源域中的类别及类别之间关系（各类别的判别概率）也迁移到目标域的任务空间中**，文章提出的深度迁移网络就是基于这一点，期望于同时迁移域、任务，来帮助对目标域的任务判别。边缘对齐好说，之前这么多方法都是边缘对齐，那如何类别对齐呢？作者提出了一个叫做"soft label"的东西来帮助目标分类器优化，而这个"soft label"则是根据源域分类器产生的。好了，文中框架的主要工作也是这两个：

* 通过域融合完成域对齐

* 通过soft labels对齐源域和目标域类别

  

作者提到了两种层次的transfer：

- domain transfer：就是适配分布，特别地是指适配marginal distribution，但是没有考虑类别信息。如何做domain transfer：在传统深度网路的loss上，再加另一个confusion loss，作为classifier能否将两个domain进行分开的loss。两个loss一起计算，就是domain transfer。
- task transfer：就是利用class之间的相似度，其实特指的是conditional distribution。类别之间有相似度，要利用上。类别之间的相似度：比如一个杯子与瓶子更相似，而与键盘不相似。文章的原话：it does not necessarily align the classes in the target with those in the source. Thus, we also explicitly transfer the similarity structure amongst categories.

现有的深度迁移学习方法通常都**只是考虑domain transfer**，而没有考虑到**类别之间的信息**。如何把domain和task transfer结合起来，是一个问题。

文章算是对Hinton的distilling knowledge的extension，把那些东西扩展到深度网络上。

## 2. 网络结构

### 2.1 和GAN的联系

![image-20220923145334453](D:\markdown file\截图\image-20220923145334453.png)

![image-20220831123100392](D:\markdown file\截图\image-20220831123100392.png)

![image-20221018193507962](D:\markdown file\截图\image-20221018193507962.png)

其实作者的这个网络很像GAN的结构，在思想上也基本一致，GAN是输入噪声，通过更新生成器参数生成和真实图片相似的图片，这里是输入目标域的图片，通过更新生成器参数生成和源域图片特征相似的图片。

首先源域的图片可以看作是GAN里面真实的图片，目标域的图片可以看作是GAN输入到生成器的噪声。

GAN里面是把真实图片和经过生成器的图片放入判别器判别，在作者这里是把源域的图片和目标域的图片都放入生成器，分别生成源域的特征和目标域的特征，再把这两组特征放入判别器判别。

在GAN的训练过程中，是先训练判别器再训练生成器（实际上这个顺序无所谓），作者的这个网络逻辑是一样的，但是细节有所差异，~~先用源域的数据把整个CNN网络训练好，图中的CNN网络就是conv1到fc8的8层网络，可以看见是先把生成器和标签预测器训练好，再把生成器固定，训练判别器。~~作者这个网络的训练过程是并行的，就是同步训练生成器、判别器、标签预测器。

和GAN唯一不同的是作者这个网络后面加了一个标签预测器。

### 2.2 实验目标、实验设置

源域是有标签的数据集，目标域是一部分有标签，一部分没标签的数据集。

目标是产生一个类别分类器θ~C~，能够在测试时正确地对目标样例进行分类，就是目标域的数据用这个网络进行分类效果和用源域的数据一样好。

### 2.3 训练过程、损失函数

lay 1-7 是五层cnn+两层全连接层，网络参数是θ~repr~，fcD 参数是θ~D~，fc8参数是θ~C~。



**第一步的流程图：**

![image-20220924140331926](D:\markdown file\截图\image-20220924140331926.png)

框架是在Alexnet的基础上改动而成，前7层是一个标准的卷积神经网络，而需要做的第一步就是将在源域数据上搭建的卷积网络根据源域有标签数据训练好，或者直接拿预训练好的网络，这是一个正常的有监督卷积网络训练过程，其损失函数优化如下：

<img src="D:\markdown file\截图\image-20220924140058475.png" alt="image-20220924140058475" style="zoom:67%;" />

注意只用源域的数据不用目标域的数据，θ~repr~是lay 1-7参数，θ~C~ 是fc8的参数，p~k~表示经过fc8后产生的类别概率，k是分类的类别数，分号前表示输入的参数，分号后表示要更新的参数。



**第二步流程图：**

<img src="D:\markdown file\截图\image-20220924151949955.png" alt="image-20220924151949955" style="zoom:67%;" />

<img src="D:\markdown file\截图\image-20221017153614737.png" alt="image-20221017153614737" style="zoom:67%;" />

**他的更新是和GAN差不多的迭代更新，生成器loss叫做域混淆loss，判别器loss叫做域判别loss。**

那怎么完成域对齐呢？所基于的思想是啥？----运用生成对抗网络的一种思想，如果一个分类器无法分辨出输入是来自源域还是来自来自目标域的时候，就认为二者已经达到域对齐了。思路已经很清晰了，作者在框架第7层后加了一个域分类器或者叫判别器—fcD，用于判别第七层出来的特征表示是属于源域还是目标域，当fcD无法分辨的时候，他们就已经到达了那个传说中的境界----雌雄同体（域对齐，也是域融合，也是域适应），哈哈。还有一个细节就是，fcD是个典型的二分类器，标签就是域标签（例如1表示源域，0表示目标域），判别器的损失函数如下：

<img src="D:\markdown file\截图\image-20220924141128584.png" alt="image-20220924141128584" style="zoom:67%;" />

其实与上面那个损失函数类似，只不过是把标签换成了域标签。
q和上面的p类似，是域分类器fcD的softmax输出。为了让两个域达到最大融合，提取到更好的域不变(domain invariance)特征以致于最好的域分类器在这些特征上都变现的很差，作者又加了一个损失函数：

<img src="D:\markdown file\截图\image-20220924141433755.png" alt="image-20220924141433755" style="zoom:67%;" />

啥意思呢？就是在上一步优化了分类器D的基础上，再去优化参数θ~repr~，这就是一个典型的交叉熵形式。1/D是域概率，q~d~ 是预测概率，实际上1/D有没有无所谓毕竟就是一个常数，让1/D = 1也可以。

上面两个损失函数是对立的，所以**要迭代更新**，同时最小化两个损失函数。

<img src="D:\markdown file\截图\image-20220924143347490.png" alt="image-20220924143347490" style="zoom:67%;" />

如何迭代呢？参考GAN。

<img src="D:\markdown file\截图\image-20220909100657671.png" alt="image-20220909100657671" style="zoom:67%;" />

好了，域对齐OK了，接下来就是作者提出来的用soft label进行任务对齐了。



**第三步流程图：**

![image-20220924151743522](D:\markdown file\截图\image-20220924151743522.png)

上面提到soft labels由源域分类器产生，然后通过soft labels优化目标任务空间，而不是像正常的图像标签。那么soft label怎么来呢？上面提到了将源域的类别即类别之间的关系迁移到目标域中，当然是用源域的类别信息来做为soft label最合适不过，文中将soft label定义为源分类器对源域中类别k的样本的softmax结果取均值，如下图所示：

<img src="D:\markdown file\截图\image-20220924145900180.png" alt="image-20220924145900180" style="zoom:67%;" />

如原图中所示，假设共有5类（Bottle、Mug、Chair、Laptop、keyboard），对模型识别所有属于瓶子类别的样本的softmax值(5个概率)进行平均，像图中得到这个平均值(图中最右边)就是得到的一个soft label（一种关系的衡量，比如在这里是瓶子的概率最高，马克杯的概率次之，其他几种基本不是）。好了，现在soft label也得到了，怎么优化呢？首先，需要给出优化函数，如下：

<img src="D:\markdown file\截图\image-20220924150026485.png" alt="image-20220924150026485" style="zoom:67%;" />

其实也是和上面的损失函数类似的，同样是交叉熵形式，其中 l~i~ 表示soft label，因为数据集中目标域也存在部分带标签数据，所以这里和有监督的优化类似，无标签的怎么办呢？丢掉？还是把预测出来的当标签？文章里没提出来，不知道。这里的p是目标域数据预测后输出的logits再除以T放入softmax的结果。

<img src="D:\markdown file\截图\image-20220924150733050.png" alt="image-20220924150733050" style="zoom:67%;" />

最后是损失函数的一个汇总：

<img src="D:\markdown file\截图\image-20220924183644699.png" alt="image-20220924183644699" style="zoom: 67%;" />



## 3. 实验

### 3.1 实验数据集

Office数据集是三个不同域（Amazon、DSLR和Webcam）的图像集合，其中最大的图像有2817个标记图像。数据集中的31个类别由办公室设置中常见的对象组成，如键盘、文件柜和便携式计算机。

### 3.2 监督的实验结果

![image-20220925151048371](D:\markdown file\截图\image-20220925151048371.png)

这证明了当目标域有标签，源域+目标域数据做CNN微调效果就不错了，但是加上dom confusion + soft labels 可以使性能进一步提升。

![image-20220925152458383](D:\markdown file\截图\image-20220925152458383.png)

我们发现，当目标域中每个类别的标记训练示例很少时，我们的方法最有效。随着我们增加目标中标记示例的数量，finetune策略开始接近自适应方法的性能。这表明，当目标域每个类别拥有合理数量的有标签的样本时，直接联合源域和目标域的数据进行微调是一种可行的适应方法。但是在有限的源域有标签数据的设置中，DA是至关重要的。

![image-20220922140028136](D:\markdown file\截图\image-20220922140028136.png)

再看看看[4]中的实验，其实作者这里就是说，遇到篮圈的这种情况，直接用DA的方法效果比freeze和finetune的效果都好。

### 3.3 半监督实验的结果

![image-20220925151703480](D:\markdown file\截图\image-20220925151703480.png)

我们的方法都优于基线。



### 3.4 用图像解释域不变（特征对齐）和类别对齐

![image-20220925153952538](D:\markdown file\截图\image-20220925153952538.png)

这是特征对齐。

![image-20220925154041569](D:\markdown file\截图\image-20220925154041569.png)

这是类别对齐，红色是正确分类的概率，可以看见加soft labels 后，正确分类的概率上升了不少。
