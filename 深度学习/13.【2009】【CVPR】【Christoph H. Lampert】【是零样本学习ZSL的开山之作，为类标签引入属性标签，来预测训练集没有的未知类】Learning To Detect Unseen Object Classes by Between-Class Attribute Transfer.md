## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\13.【2009】【CVPR】【Christoph H. Lampert】【是零样本学习ZSL的开山之作，为类标签引入属性标签，来预测训练集没有的未知类】Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer.pdf)

### 1.1 在干什么、有什么贡献、什么结论

<img src="D:\markdown file\截图\image-20221008142250834.png" alt="image-20221008142250834" style="zoom:50%;" />

**背景：没有目标域**

**本篇paper为ZSL（zero-shot-learning）的开山之作**，算是迁移学习的一种情况，与DG类似。主要介绍了一个问题：如何检测未在训练集中出现的样本。

本文在2009年提出，主要意思就是我们做图像分类任务太依赖训练样本了，如果出现训练集中没有的类别，模型效果就大幅下降，怎么办呢？作者就提出了我们要基于属性分类（attribute-based classifification），遇到未知类我们可以根据它们的属性表示来检测新类。为了学习这些属性，我们可以通过合并几个类的图像来利用现有的训练数据。例如条纹属性，我们可以使用斑马，蜜蜂和老虎的图像。

**给出了一个数据集The Animals with Attributes** **Dataset**

## 2. 具体方法

**一些符号：**设(x1,l1),...,(xn,ln)为训练样本 x 和相应类别标签 l 的成对数据，数量为n。训练集总共有K个类别，用Y={y1,...,yK}表示，测试集总共有L个类别，用Z={z1,...,zL}表示。Y为训练集中所包括的类别，Z为测试集中所包括的类别，两者没有交集。a为属性向量，一共有M个属性，用a={a1,...,aM}表示，算法的目的是学习一个分类器f:X -> Z。
**背景：**普通的分类器（如下图左边）对于训练集的每个类别y1,...,yK都学习了相应的参数α1,...,αK，但是对于测试集的未知类z1,...,zL并没有学习到相应的参数，所以说肯定不能预测未知类。为了预测未知类，就需要建立X于Z之间的联系，因为训练时，并没有任何关于Z的信息。因此作者提出可以建立一个人工定义的属性层A，这里要注意的是该属性层需要能够较好地表现样本的类别信息，而且它定义起来不能太过繁杂，要不然有这功夫，还不如直接给样本Z打上标签，共分类器学习了。比如可以定义属性层包括属性“黑色”、“有尾巴”之类区具有高归纳性的属性。其实整个算法的精髓也就在于这个属性层A，通过这个属性层，将原本基于图片低维特征的分类器，转变为基于高维语义特征（属性层）的分类器，使得训练出来的分类器，分类能力更广，有突破类别边界的能力。可以类比人的思维方式，当人遇到没见过的东西的时候，虽然不会知道它的名字和所属类别，但是能够抽象出它的高维特征。

![image-20221008202918197](D:\markdown file\截图\image-20221008202918197.png)

**模型结构：**作者提供了两种模型（中间和右边），均可以达到迁移学习的效果。

第一种为DAP：直接属性预测(Direct attribute prediction DAP)。如图所示，在样本和训练类标之间加入一个属性表示层A，利用监督学习方式，可以学习到从x生成A的属性参数β。在测试阶段，就可以利用属性表示层A，来表示测试数据产生的类别Z，从而实现迁移学习。

第二种为IAP：间接属性预测(Indirect attribute prediction IAP)。如图2所示，在训练阶段，和传统的监督训练一样，只是在其标签Y上，学习一层属性表示层A，在测试阶段，利用标签层Y和属性层A可以推测出测试数据的类别Z。

**两种结构的比较：**对于DAP，测试时，其依据仅仅是属性层；而对于IAP，训练样本的类标也作为一个中间层，它能够一定程度上限定测试样本生成新类标的范围，使得学习到的连接控制在对于Y来说，有意义的范围内，因此可以增强系统的鲁棒性。**但实际上，在作者后面的实验中，DAP的效果要比IAP的效果好很多，最终DAP的准确率为40.5%，IAP的准确率为27.8%。由于前者高很多，因此作者之后的实验和结果讨论都建立在DAP之上。所以说我们主要看DAP方法。**

<img src="D:\markdown file\截图\image-20221009141947609.png" alt="image-20221009141947609" style="zoom:50%;" />

**总结一下这个过程：**首先，训练时每一个训练类别Y都可以表示为长度为m的属性向量ay=(a1,...,am)，测试时每一个类别Z也可以用一个属性向量az=(a1,...,am)表示。中间属性层A是事先人工定义好的，也就是说，对于训练类别Y可以表示成属性向量ay的形式，同样测试类别Z也可以表示为属性向量az的形式。这个属性层的定义要求不太繁琐，而且能够较好地反映出类别的性质。对于DAP来说，先训练一个分类器X->A，利用训练集Y对应的属性向量进行训练。测试时，即可得到测试样本对应的属性向量A，对比测试集Z类别的属性向量，即可得到对于unseen数据的预测类别。

## 3. 数据集介绍

<img src="D:\markdown file\截图\image-20221008142250834.png" alt="image-20221008142250834" style="zoom:50%;" />

**数据集的简介。**

![image-20221008210232961](D:\markdown file\截图\image-20221008210232961.png)

**上图为属性向量也可以看作属性标签。**

<img src="D:\markdown file\截图\image-20221009141133323.png" alt="image-20221009141133323" style="zoom:50%;" />

**数据集中类别和属性的对应关系。**

