## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\16.【2014】【arXiv】【Eric Tzeng、Hoffman】【UC伯克利】【DDC，将MMD用在了倒数第二层】Deep Domain Confusion Maximizing for Domain Invariance.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**背景：目标域无监督。**

<img src="D:\markdown file\截图\image-20221016145308491.png" alt="image-20221016145308491" style="zoom:50%;" />

在一个新的领域中对深度模型进行微调可能需要大量的数据，而对于许多应用来说，这些数据是不可用的。我们提出一种新的CNN架构，它引入了一个适应层和一个额外的domain confusion损失。

优化domain的invariance可以被认为等同于学习预测类标签的任务，同时尽可能找到表征相同的域。这一原则构成了我们所提议的方法的实质。我们通过对损失进行优化来学习深度表示，损失包括标记数据上的分类错误和domain confusion损失，domain confusion损失旨在使域无法区分。
## 2. 网络结构

<img src="D:\markdown file\截图\image-20221016143510324.png" alt="image-20221016143510324" style="zoom:50%;" />

**网络结构：**我们提出了一种新的CNN架构，如图1所示，该架构使用了一个自适应层和一个基于最大平均偏差(MMD)的domain confusion损失来自动学习一个联合训练的表示来优化分类和域不变性。
我们的结构既可以解决有监督adaption(当有少量目标标记数据可用时)问题，也可以解决无监督adaption(当没有标记目标训练数据可用时)问题。

<img src="D:\markdown file\截图\image-20221016181129675.png" alt="image-20221016181129675" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221016181137643.png" alt="image-20221016181137643" style="zoom:50%;" />

**损失函数：**Lc表示分类损失，MMD表示源域和目标域差距的损失。

**训练过程：**把预训练好的网络拿来，在同时训练分类器和MMD损失。