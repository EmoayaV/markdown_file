![image-20220907165349925](D:\markdown file\截图\image-20220907165349925.png)

之前的GAN随即输入向量产生一张图片，不能控制输出的图片是什么，于是就产生了Conditional GAN。

## 1. text-to-image 任务

![image-20220907194028108](D:\markdown file\截图\image-20220907194028108.png)

如果输入一段文字，输出相应的图片，用传统的方法是把文字通过一个神经网络生成相应的图片，但是这样做有一些问题，就是一段文字对应的场景有多种多样，比如输入一辆火车，那么生成的图片可能是正面的火车，也可能是侧面的火车，最后生成的图片可能是正面火车和侧面火车的平均，就会使图片模糊。所以要用到GAN的技术，GAN不会使图片模糊。

![image-20220911105557877](D:\markdown file\截图\image-20220911105557877.png)

![image-20220911111401939](D:\markdown file\截图\image-20220911111401939.png)

CGAN和原始GAN最大的区别就是，原始GAN生成器输入的是噪音，而CGAN输入的是噪音+条件。

并且在判别器也要输入条件，如果不输入条件，那么判别器就会将接近真实的照片置为1，不真实的照片置为0，这样一来生成器附带的条件就没什么用了。所以要在判别器的输入也加上条件。

比如：生成器的输入是（火车，火车图片），（猫，猫的图片），判别器的输入是（火车图片），（猫的图片）并且给真实火车、猫的图片打了高分，生成器输出的火车、猫的图片打低分。那么当生成器的输入是（火车，猫的图片），判别器的输入是（猫的图片），这样判别器也会给他打高分，因为高分的依据是图片是不是接近真实，而没有考虑条件和图片是否匹配。

![image-20220911112014783](D:\markdown file\截图\image-20220911112014783.png)

上图为算法流程。

![image-20220911112431410](D:\markdown file\截图\image-20220911112431410.png)

discriminator的两种架构，上图下面的架构更好。

![image-20220911113035401](D:\markdown file\截图\image-20220911113035401.png)

对于text to image任务，还有一种stack GAN的网络，了解即可。



## 2. image-to-image 任务

![image-20220911120000368](D:\markdown file\截图\image-20220911120000368.png)

![image-20220911120311103](D:\markdown file\截图\image-20220911120311103.png)

![image-20220911120515293](D:\markdown file\截图\image-20220911120515293.png)

前面的情况都是把文字作为条件，也可以把图片作为条件，

传统方法还是老问题，输出的图片模糊，因为是多张图片的平均。 

![image-20220911120704654](D:\markdown file\截图\image-20220911120704654.png)

对于image to image问题，还有一种patch GAN



## 3. speech enhancement 任务

![image-20220911120858080](D:\markdown file\截图\image-20220911120858080.png)

![image-20220911120950503](D:\markdown file\截图\image-20220911120950503.png)

GAN还可以用于语音增强，语言去噪，语音生成等等方面。



## 4. video generation 任务

![image-20220911121052578](D:\markdown file\截图\image-20220911121052578.png)

GAN还可以用于视频生成。
