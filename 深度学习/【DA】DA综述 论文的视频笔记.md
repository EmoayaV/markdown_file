# 迁移学习

## 1. 从迁移学习到DA的介绍

### 1.1 什么是迁移学习

![image-20220831153406379](D:\markdown file\截图\image-20220831153406379.png)

迁移学习有两域，源域和目标域，这两个域的数据不同，任务不同。 



### 1.2 什么是DA

![image-20220831153835941](D:\markdown file\截图\image-20220831153835941.png)

DA是迁移学习的一个子问题，DA研究的场景是任务一样，数据不一样。

![image-20220831154005351](D:\markdown file\截图\image-20220831154005351.png)

![image-20220831154252664](D:\markdown file\截图\image-20220831154252664.png)

源域到目标域的分布不同，具体指源域的数据经过特征提取后和目标域的数据经过特征提取后的特征分布不同，DA就是把源域和目标域的特征对齐，使源域的分类边界可以用到目标域。

![image-20220831154440853](D:\markdown file\截图\image-20220831154440853.png)

DA的任务可以分为好几类，首先分为多步迁移和单步迁移，单步用的最多。单步迁移分为同构和异构，同构指图片和图片的关系，异构指图片和文字的区别。同构中根据目标域有没有标签又可以分为监督、无监督和半监督。

![image-20220831155203045](D:\markdown file\截图\image-20220831155203045.png)

DA的方法可以分为好几类，可以在特征、实例和模型上适应，现在用的最多的是特征上的自适应。

![image-20220831155454506](D:\markdown file\截图\image-20220831155454506.png)

在特征自适应的基础上，又有三大主流方法，基于对抗、基于差异和基于重构的，这些方法的目的都是把源域和目标域的特征对齐，使源域的分类边界可以用到目标域。

**总结**：DA在源域和目标域的任务相同，数据不同的场景下使用的最多，目标域大多是无标签的数据。最主流的三大方法是基于对抗、基于差异和基于重构，这三大方法都是基于特征层面的DA。



## 2. DA方法的介绍

### 2.1 目标域有标签是可以用fine-tune

![image-20220831164425240](D:\markdown file\截图\image-20220831164425240.png)

这篇文章的主要贡献是证明了神经网络的前几层一般用来提取边缘、纹理的特征，特征更加通用，比如说提取出了特征毛茸茸的耳朵，这个特征可以用于猫、狗、兔子等等的任务。

后面几层一般用来提取全局、语义的特征，也就是说把边缘、纹理的特征组合起来，得到适用于某个特定任务的语义特征、全局特征，此时这个特征只适用于特定任务，所以也不通用。比如提取出的特征是毛茸茸的耳朵、长尾巴、长胡须、喵喵叫四个特征的组合，那么就只能用于猫的任务，不能用于狗、兔子等等的任务。



### 2.2 目标域没有标签，这是DA研究的主流方向

#### 2.2.1 几种用于衡量源域和目标域数据分布差异的loss

![image-20220831171411158](D:\markdown file\截图\image-20220831171411158.png)



#### 2.2.2 DDC方法

![image-20220831171337511](D:\markdown file\截图\image-20220831171337511.png)

![image-20220831171622049](D:\markdown file\截图\image-20220831171622049.png)

![image-20220831172338749](D:\markdown file\截图\image-20220831172338749.png)



#### 2.2.3 DAN方法

![image-20220831172427499](D:\markdown file\截图\image-20220831172427499.png)



#### 2.2.4 RTN方法

![image-20220831172509984](D:\markdown file\截图\image-20220831172509984.png)



#### 2.2.5 JAN方法

![image-20220831172707202](D:\markdown file\截图\image-20220831172707202.png)



#### 2.2.6 RevGrad方法

![image-20220831173108224](D:\markdown file\截图\image-20220831173108224.png)

![image-20220831173206325](D:\markdown file\截图\image-20220831173206325.png)



#### 2.2.7 iCAN方法

![image-20220901114744722](D:\markdown file\截图\image-20220901114744722.png)



#### 2.2.8 MADA方法

![image-20220901115210852](D:\markdown file\截图\image-20220901115210852.png)

![image-20220901115440583](D:\markdown file\截图\image-20220901115440583.png)



#### 2.2.9 WAN方法

![image-20220901120310688](D:\markdown file\截图\image-20220901120310688.png)



#### 2.2.10 DRCN方法

![image-20220901120447983](D:\markdown file\截图\image-20220901120447983.png)



#### 2.2.11 DSN方法

![image-20220901120625107](D:\markdown file\截图\image-20220901120625107.png)

![image-20220901120959972](D:\markdown file\截图\image-20220901120959972.png)



#### 2.2.12 Tri-training方法

![image-20220901121134332](D:\markdown file\截图\image-20220901121134332.png)



#### 2.2.13 EHTS+APA方法

![image-20220901121516781](D:\markdown file\截图\image-20220901121516781.png)

![image-20220901121714888](D:\markdown file\截图\image-20220901121714888.png)



#### 2.2.14 其他方法

![image-20220901121932761](D:\markdown file\截图\image-20220901121932761.png)



