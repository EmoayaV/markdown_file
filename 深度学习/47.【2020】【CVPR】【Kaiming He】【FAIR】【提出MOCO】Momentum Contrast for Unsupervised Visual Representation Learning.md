## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\47.【2020】【CVPR】【Kaiming He】【FAIR】【提出MOCO】Momentum Contrast for Unsupervised Visual Representation Learning.pdf)

### 1.1 在干什么、有什么贡献、什么结论

问题：无监督的视觉方法

解决：采用对比学习方法来做无监督学习

### 1.2 什么是对比学习

<img src="D:\markdown file\截图\image-20221231154348764.png" alt="image-20221231154348764" style="zoom:50%;" />

对比学习就是对比着学习，模型不需要知道图片1、2是人，图片3是狗，只用知道图片1、2相似，与图片3不相似就行。比如把这三张图片放入一个模型M提取特征，得到f1、f2、f3三个特征，在最终的特征空间内，我们希望对比学习能把图片1、2的特征拉近，并远离图片3的特征。如果能做到类似的物体在特征空间内相邻的区域，不类似的物体在特征空间内不相邻的区域，目的就达到了，会学到很好的特征。

那么对比学习不需要知道具体的标签信息，但还是要知道图片1、2相似，与图片3不相似吗，这不还是需要监督信息吗？为什么对比学习会认为是无监督的训练方式呢？

因为大家可以设计一些代理任务（pretext task），人为定义一些规则，这些规则从而定义那些图片相似，哪些图片不相识，从而提供监督信号来训练模型，这就是所谓的自监督训练。比如InstDist（instance discrimination）代理任务，将同一张图片经过不同处理得到的两张图片当作正样本，实现数据集中所有的图片当作负样本。

对比学习最厉害的地方在于灵活性，只要能找到一种方式定义正负样本就够了，剩下的操作都比较标准，比如在视频领域，同一个视频的任意两针可以认为是正样本，其他视频的所有针可以认为是负样本。

### 1.3 什么是动量

<img src="D:\markdown file\截图\image-20221231160110835.png" alt="image-20221231160110835" style="zoom:50%;" />

动量可以理解为

y~t~ = m * y~t-1~ + (1-m) * x~t~

就是说我当前时刻的输出不光依赖于这一时刻的输入，还依赖于上一时刻的输出。

## 2. 具体细节

<img src="D:\markdown file\截图\image-20221231162312605.png" alt="image-20221231162312605" style="zoom:50%;" />

作者虽然用到了对比学习，但是他们把对比学习看作一个字典查询任务。

<img src="D:\markdown file\截图\image-20230101134709511.png" alt="image-20230101134709511" style="zoom:50%;" />

将对比学习当作动态字典查询，字典最好保持两个特性，第一是字典要大，二是字典中的key要保持一致性，字典越大模型就会学到视觉信息就越来越丰富，就更容易学到本质特征，字典中的key也应当用相同或者相似的编码器得到，这样一来，当key和query做对比时才可能保证这个对比尽可能一致，如果是用不同编码器得到的key，那么这个query就可能找到了和他相同或者相似编码器的key，而不是含有相同语义信息的key。

<img src="D:\markdown file\截图\image-20230101141608491.png" alt="image-20230101141608491" style="zoom:50%;" />

作者提出moco就是为了构造一个又大又一致的字典，具体来说就是用队列的方式去构造字典。首先字典要大就证明在一个batch中输入的样本数要多，但是受限于现存的大小，注定字典就不能太大，所以要想一个办法把字典大小和batch大小剥离开，这个办法就是用队列（queue）的数据结构。具体方法是：这个队列可以很大，但是我们每次更新这个队列呢是一点一点进行的，也就是说当我们用很小的batchsize时，现在这个batch抽到的特征进入队列，把最早的batch的特征移除队列，这样就把batchsize和队列大小分开了，最后这个队列的大小，也就是字典的大小可以设置的非常大。

字典光大是不够的，还要保持一致性，就是说所有的key最好用一个编码器的到。所以作者用了momentum encoder来解决这个问题，就是说我们的momentum encoder虽然一开始是由encoder（得到query的encoder）初始化而来，但是如果选择一个非常大的动量m，那么这个momentum encoder更新的其实是非常缓慢的，不会跟着encoder而快速改变，从而保证字典中的所有key都是又相似的编码器得到的，尽可能保持key之间的一致性。

基于上面两点，所以moco可以构造又大又一致的字典，从而无监督学习视觉表征。

<img src="D:\markdown file\截图\image-20230101142309000.png" alt="image-20230101142309000" style="zoom:50%;" />

说完了如何构造字典，剩下的就是选择代理任务，去充当自监督信号，从而进行模型的训练了。moco实际上非常灵活，可以选择不同的代理任务，本文选择了instdisc任务。instdisc任务简单来说就是：如果一个query和key是同一个图片的不同视角（比如不同的随机剪裁得到的），那么这个query和key就可以配对，剩下的query和key都不能配对。结果就是我们无监督训练的模型比有监督训练的模型要好。

<img src="D:\markdown file\截图\image-20230101142842116.png" alt="image-20230101142842116" style="zoom:50%;" />

相关工作：作者说其实无监督学习和自监督学习的意思差不多，这里就无监督学习来表示这个意思。那么在自监督学习中呢，主要有两个方面的工作可以做，第一是在辅助任务的设计上下功夫，另一个是在损失函数上下功夫，那么moco就是在损失函数上下功夫，他提出的又大又一致的字典主要影响后面infoNCE损失函数的计算。

<img src="D:\markdown file\截图\image-20230101150316663.png" alt="image-20230101150316663" style="zoom:50%;" />

作者这里主要选取了infoNCE损失，这个损失满足当前query和配对key相似，且query和其他不配对key不相似时，loss要小，反之loss变大。

如果使用softmax计算loss，那么其分母的类别K将是一个巨大的数字，比如imagenet有128W图片，那么分母的类别K就是128W个类别，为了降低类别数量就用了NCEloss。

NCEloss例子：

假设当前用户行为 abcd->e，

则正样本是e，负样本（召回时从其他用户点击中随机选择的）h、m、n。

共有(1+k)个样本。这里是(1+3)个样本。

就这一条，batchsize=1来说，损失函数如下：

<img src="D:\markdown file\截图\image-20230101145243573.png" alt="image-20230101145243573" style="zoom:50%;" />

NCEloss是把所有类别转为两类，正样本（data sample）是一类，所有负样本（noise sample）作为一类。但是如果把数据集剩下的样本作为负样本，即使解决了类别多的问题，其计算复杂度还是没有降下来，那么怎么算快点呢，就只能取近似了，具体来说就是与其在整个数据集上算loss，不如我在负样本中选一些做loss就可以了。那么NCE的主要目的呢就是把超多分类的问题转换为二分类问题，从而还可以使用softmax操作。

那么infoNCE是什么意思，他是NCE的变体，他觉得如果只把问题看作一个二分类是不合理的，在如此多的噪声样本里，大家很可能不是一个类（负类之间亦有差异），所以还是看成一个多分类比较合理。如下：

<img src="D:\markdown file\截图\image-20230101150218131.png" alt="image-20230101150218131" style="zoom:50%;" />

实际上呢，这个infoNCE其实就是celoss，只不过在softmax中，K指的是类别数，而infoNCE中 K指的是负样本的数量，分母是一个正样本+k个负样本的和。直观的想一想，这个infoNCE其实就是celoss，做的就是K+1类的分类任务，目的就是把query这个图片分到 k~+~ 这个类别。这个K目前看来是队列的长度。

<img src="D:\markdown file\截图\image-20230101151257300.png" alt="image-20230101151257300" style="zoom:50%;" />

moco的核心就是把字典用一个队列表示出来，将一个队列（queue）作为字典，里面的元素就是key，训练过程呢就是新的key进来，老的key出去，从而与batch大小解耦。队列的意思就是新的进来老的除去，所以也被称作FIFO（first in first out）的数据结构。

<img src="D:\markdown file\截图\image-20230101152131685.png" alt="image-20230101152131685" style="zoom:50%;" />

动量更新。

<img src="D:\markdown file\截图\image-20230101133107464.png" alt="image-20230101133107464" style="zoom:50%;" />

![image-20230101153756837](D:\markdown file\截图\image-20230101153756837.png)

字典又大又一致是很难做的，之前的方法只能保证其中之一

比如end to end 的对比学习方法（key和query使用相同的encoder，xq和xk来自一个batch，一个前向传播同时得到key和query的特征，两个encoder同时使用梯度回传）只能保证一致性，而不能保证字典的大小，因为字典大小和batch大小绑定了，如果字典想达到1W，那么batchsize也要设置为1W，首先GPU是塞不下这么大的batch的，就算塞得下，大batchsize也是非常难优化的，不易收敛，这个方法代表有SimCLR，他们这么做是因为有TPU，选择8192做batchsize。

再比如memory bank的对比学习方法只能保证字典大小，不能保存一致性。在训练时，随机抽选多个样本特征作为字典，参与计算，在计算完成后，用更新的encoder再去更新抽出来的样本特征，这样做肯定保证不了一致性。moco其实和memory bank比较相似。

<img src="D:\markdown file\截图\image-20230101133107464.png" alt="image-20230101133107464" style="zoom:50%;" />

提出带有动量的对比网络来维持对比样本的一致性。如图所示，其实encoder 可以是来自同一个encoder，也可以是来自不同的encoder.图1（a）是常见的对比损失方法，拿出xq和xk做点积，计算xq和xk的相似度。但这种方式局限于batch_size的大小，只能与batch_size范围内的样本进行对比。图1(b)是一种memory bank的方式，把所有的样本（例如ImageNet-1K）都放在memory bank中，那memory bank存放着1M*feature 的数据（大约600M）。但这种方式也有不足之处，缺少了一致性。假设batch_size为1，每次更新只更新一个样本，此时的encoder已经经过backward回传更新了，剩下的999999个样本与当前的encoder已经丢失一致性了（因为是在不同时刻的encoder产生的），如果把整个队列都更新一遍，最新的样本的最旧的样本差距是很大的。因此提出带有动量的更新方式。Moco是一个折中的方式，既保留了一致性，也维持了样本容量要大的特点。它创建了一个队列，做对比的时候只与队列中的数据进行对比。同时用了动量的方式，每次momentum encoder不是完全=encoder，而是通过公式：θk← mθk + (1− m)θq.进行更新，m通常为0.999，这样能保证每次的更新不是很大，保持一致性。
<img src="D:\markdown file\截图\image-20230101154813356.png" alt="image-20230101154813356" style="zoom:50%;" />

伪代码。
