## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\50.【2019】【arXiv】【Aaron van den Oord】【谷歌】【对比学习，提出生成型的代理任务】Representation Learning with Contrastive Predictive Coding.pdf)

### 1.1 在干什么、有什么贡献、什么结论

主要关注一下CPC的代理任务，用预测的任务去做对比学习。

一般机器学习呢分为判别式模型和生成式模型，那么前面介绍的InstDisc和InvaSpread两篇文章呢都用了个体判别任务，显然属于判别型的代理任务，那么本文呢就提出了生成型代理任务CPC。

 ## 2. 具体细节

<img src="D:\markdown file\截图\image-20230104174332898.png" alt="image-20230104174332898" style="zoom:50%;" />

CPC不光可以用在音频，还可以是图片、文字，简单起见以音频信号为例。大概的想法是我们有一个时序的序列，我们将之前时刻的输入（xt-3、xt-2， ..， xt）全部送给一个编码器genc（encoder），得到了一些特征，然后我们把这些特征送给一些自回归的模型gar（autoregression），常见的自回归模型有RNN、LSTM，每一步最后的输出就会得到上图红色的东西，就是ct，context representation。代表上下文的一个特征表示，如果这个上下文的特征足够好，那么就可以做出一些合理的预测，所以就可以利用这个ct去预测未来时刻的特征（zt+1、zt+2、..）那么对比学习体现在何处呢？那么这里的正样本就是未来的输入（xt+1、xt+2、..）经过编码器genc后得到的未来时刻的特征输出（zt+1、zt+2、..）相当于你通过ct做出的特征输出是query，而真正未来时刻的输出呢是由这些输入决定的。就是说（zt+1、zt+2、..）相对于通过ct得到的预测来说呢是正样本，负样本的定义非常广泛，比如你可以任意选取输入，通过编码器得到输出，那么这个输出呢应该和你的预测是不相似的，这就是CPC定义正负样本的方式。