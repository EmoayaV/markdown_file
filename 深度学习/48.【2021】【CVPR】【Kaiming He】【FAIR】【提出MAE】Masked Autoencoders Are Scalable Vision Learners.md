## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\48.【2021】【CVPR】【Kaiming He】【FAIR】【提出MAE】Masked Autoencoders Are Scalable Vision Learners.pdf)

[文章解读](https://blog.csdn.net/qq_37486501/article/details/122127859)

### 1.1 在干什么、有什么贡献、什么结论

问题：无监督的视觉方法

解决：采用完形填空方法来做无监督学习，提出一种可扩展的自监督学习方法MAE：随机遮盖输入图片的子块，然后重建丢失像素

### 1.2 MAE的地位

<img src="D:\markdown file\截图\image-20230102150235715.png" alt="image-20230102150235715" style="zoom:50%;" />

MAE相当于NLP中 BERT 的地位，相当于CV中的BERT。

## 2. 具体细节

<img src="D:\markdown file\截图\image-20230102170529961.png" alt="image-20230102170529961" style="zoom:50%;" />

encoder是VIT，decoder是Transformer的block。

本文证明了掩蔽自动编码器(MAE)是一种可扩展的计算机视觉自监督学习器。
我们的MAE方法很简单：我们掩盖输入图像的随机补丁，并重建缺失的像素。
它基于两个核心设计：

首先，我们开发了一个非对称的编码器-解码器体系结构，其中的编码器只在可见的补丁子集上运行(没有掩码作用)，以及一个轻量级解码器，从潜在表示和掩码标记重建原始图像。
其次，我们发现掩蔽高比例的输入图像，例如75%，会产生一个不平凡而有意义的自我监督任务。
将这两种设计结合起来，使我们能够高效地训练大型模型:我们加快了训练(3倍或更多)，并提高了准确性。

我们的掩蔽自动编码器(MAE)是一个简单的自动编码方法，重建原始信号的部分观察。像所有的自动编码器一样，我们的方法有一个编码器，将观察到的信号映射到一个潜在的表示，和一个解码器，从潜在的表示重建原始信号。
与传统的自动编码器不同，我们采用了一种非对称设计，允许编码器只对部分观测信号(没有掩码标记)进行操作，并采用一个轻量级解码器，从潜在表示和掩码标记重新构造完整的信号。图1演示了接下来介绍的想法。
Masking掩蔽。

在ViT[16]之后，我们将图像分割成规则的非重叠的小块。
然后，我们对一个子集的补丁进行采样，并对剩余的补丁进行掩码(即删除)。
我们的抽样策略是直接的:我们抽样随机斑块，不更换，遵循均匀分布。我们称之为“随机抽样”。
高屏蔽率的随机抽样(即删除补丁速率)很大程度上消除冗余,从而创建一个不容易解决的任务由可见邻近补丁外推法(见图2 - 4)。均匀分布防止潜在的中心偏差(例如,蒙面补丁图像中心附近)。
最后，高度稀疏的输入为设计一种高效的编码器创造了机会。
MAE编码器。
我们的编码器是一个ViT[16]，但只适用于可见的，未屏蔽补丁patches。就像在标准ViT中一样，我们的编码器通过添加位置嵌入的线性投影来嵌入补丁，然后通过一系列Transformer块来处理结果集。. 然而，我们的编码器只能在一个小的子集上工作(例如，25%)。屏蔽补丁被移除;没有掩码的tokens被使用。这允许我们训练非常大的编码器，只有一小部分的计算和内存。完整的数据集由轻量级解码器处理，下面将介绍。
MAE解码器。

MAE解码器的输入是：由(i)编码的可见补丁和(ii)掩码标记组成的完整标记集。参见图1。每个掩码令牌[14]都是一个共享的、学习过的向量，表示存在一个缺失的补丁来预测。我们将位置嵌入添加到这个完整集合中的所有标记中;如果不这样做，遮罩令牌在图像中就不会有关于它们位置的信息。解码器还有另一系列Transformer块。

MAE解码器仅在预训练用于执行图像重建任务(仅编码器用于产生图像表示进行识别)。因此，解码器体系结构可以以独立于编码器设计的方式灵活设计。我们实验用非常小的解码器，比编码器窄和浅层低。例如，我们的默认解码器与编码器相比，每个令牌的计算量小于10%。采用这种非对称设计，整套令牌只由轻量级解码器处理，这大大减少了预训练时间。

重建目标。我们的MAE通过预测每个掩蔽块的像素值来重建输入。解码器输出的每个元素都是表示一个patch的像素值向量。解码器的最后一层是线性投影，其输出通道数等于一个patch中的像素值数。解码器的输出被重塑以形成重构图像。我们的损失函数计算重建和原始图像在像素空间的均方误差(MSE)。我们只计算屏蔽补丁的损失，类似于BERT [14].1
我们还研究了一种以每个掩蔽块的归一化像素值为重建目标的变量。具体来说，我们计算一个patch中所有像素的均值和标准差，并用它们来归一化这个patch。在实验中，我们采用归一化像素作为重建目标，提高了图像的表示质量。

简单的实现。我们的MAE预训练可以有效地执行，而且重要的是，不需要任何专门的稀疏操作。

首先，我们为每个输入补丁生成一个标记(通过添加位置嵌入的线性投影)。
接下来，我们将随机洗牌列表，并根据屏蔽比率删除列表的最后一部分。这个过程为编码器产生一个小的目标子集，等价于不用替换的方法采样patch。
编码后，我们将一个掩码令牌列表添加到已编码的补丁列表中，并对整个列表进行反洗牌(颠倒随机洗牌操作)，以将所有令牌与其目标对齐。
解码器被应用于这个完整的列表(添加了位置嵌入)。
如前所述，不需要进行稀疏操作。这个简单的实现引入了可以忽略不计的开销，因为拖曳和反洗牌操作是快速的。