## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\51.【2020】【CVPR】【Yonglong Tian】【MIT】【对比学习，使用了多模态的代理任务】Contrastive Multiview Coding.pdf)

### 1.1 在干什么、有什么贡献、什么结论

动机：我们人观察世界是通过很多个传感器的，比如眼睛、耳朵，这些都充当着不同的传感器来给我们的大脑提供不同的信号，每一个视角接受的信号都是带有噪声的，而且有可能是不完整的，最重要的这些信息是在这些不同的视角中共享的，比如一个狗可以被看见、听见、或者感受到，基于这个想法作者就提出了我们要学一个强大的特征，这个特征要具有视角不变性，就是说不管你给我看哪个视角，不管是看到狗还是听到狗叫声，我都可以判断出这是一条狗，所以说CMC这篇论文就是去增大互信息，就是所有视角之间的这个互信息，如果能学到一种特征，能抓到所有视角下的关键的因素，那这个特征就很好了，至少解决个分类问题不在话下。

CMC是第一个去做这种多视角的对比学习的，它不仅证明了对比学习的灵活性，而且证明了多视角、多模态的可行性，所以说OpenAI很快就出了CLIP模型。

**这篇文章实际上已经用到了多模态的信息，不过他用的是不同视角下的多模态，CLIP用的是语义的多模态。**

## 2.具体细节

<img src="D:\markdown file\截图\image-20230105151939946.png" alt="image-20230105151939946" style="zoom:50%;" />

这篇文章定义正负样本的方式就更为广泛了，他说一个物体的多个视角都可以作为正样本，作者用了NYU RGBD这个数据集，这个数据集同时又四个视角，分别是原始图像、图像对应的深度信息、语义分割信息、和surface normal信息，CMC的意思是说虽然这些不同的输入（视角）来自于不同的传感器，或者说不同的模态，但是这些图片都对应的是一张图片，都是一个东西，那他们呢就应该互为真样本，也就是说当你有一个特征空间时，那图中四个绿色的点在特征空间里就应该非常的接近，这时候再随机挑一张其他图片（无论是原始图片还是分割的图片），那这个图片产生的红色特征就应该和绿色的特征远离，所以这就是CMC定义正负样本的方式，他的正样本是来自于多个视角。一旦定义好正负样本，剩下的工作就大差不差了。

另一个要提的点，可能算一个小小的局限性，就是说当你再处理不同的视角，或者说不同的模态的时候，有可能需要不同的编码器，因为不同的输入可能长得很不一样，这就有可能会导致你使用几个视角，你就有可能得配几个的编码器，那么再训练的时候这个计算代价就有点高，比如再CLIP中，文本端就是用了一个大型的语言模型BERT，他的图像端呢就是用一个VIT，就需要有两个编码器，但是这样呢又回到了VIT中用Transformer的一个好处，就是说Transformer有可能同时处理不同的模态的数据，而事实上现在已经有人做了，再2021年ICLR就有一篇投稿，叫做MA-CLIP，他们就用一个Transformer同时处理两个输入的模态，效果反而更好，所以说这个（同时用一个编码器处理多个模态的数据）才是Transformer真正吸引人的地方，就是一个网络能处理很多类型的数据，而不用去做针对每个数据特有的改进。