## 1. 比赛简介

[31.【2022】【NIPS比赛】【比赛简介】VisDA-2021 Competition Universal Domain Adaptation to Improve Performance on Out-of-Distribution Data](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【比赛简介】VisDA-2021 Competition Universal Domain Adaptation to Improve Performance on Out-of-Distribution Data.pdf)

### 1.1 数据集介绍

<img src="D:\markdown file\截图\image-20221118154825536.png" alt="image-20221118154825536" style="zoom:50%;" />

### 1.2 评价指标

Area Under the ROC Curve (AUC) 和 Accuracy (ACC)

### 1.3 Baseline和结果

<img src="D:\markdown file\截图\image-20221118160045221.png" alt="image-20221118160045221" style="zoom:50%;" />

## 2. 第一名方法

**原文：**

[31.【2022】【NIPS比赛】【Burhan Tayyab】【第一名方法】Pre-Training Transformers for Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【Burhan Tayyab】【第一名方法】Pre-Training Transformers for Domain Adaptation.pdf)

[31.【2022】【NIPS比赛】【Burhan Tayyab】【第一名方法的PPT】Pre-Training Transformers for Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【Burhan Tayyab】【第一名方法的PPT】Pre-Training Transformers for Domain Adaptation.pdf)

**参考文献：**

[35.【2022】【arXiv】【Hangbo Bao】【微软】【实际上就是VIT+类似于BERT的自监督训练】BEIT BERT Pre-Training of Image Transformers](C:\Users\Emoaya\Desktop\文章\精读文章\35.【2022】【arXiv】【Hangbo Bao】【微软】【实际上就是VIT+类似于BERT的自监督训练】BEIT BERT Pre-Training of Image Transformers.pdf)

[36.【2017】【NIPS】【Ashish Vaswani】【谷歌】【提出Transformer】Attention Is All You Need](C:\Users\Emoaya\Desktop\文章\精读文章\36.【2017】【NIPS】【Ashish Vaswani】【谷歌】【提出Transformer】Attention Is All You Need.pdf)

[37.【2018】【arXiv】【Jacob Devlin】【谷歌】【提出BERT】BERT Pre-training of Deep Bidirectional Transformers for Language Understanding](C:\Users\Emoaya\Desktop\文章\精读文章\37.【2018】【arXiv】【Jacob Devlin】【谷歌】【提出BERT】BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf)

[38.【2020】【arXiv】【Alexey Dosovitskiy】【谷歌】【提出Vision Transformer】An image is worth 16x16 words Transformers for image recognition at scale](C:\Users\Emoaya\Desktop\文章\精读文章\38.【2020】【arXiv】【Alexey Dosovitskiy】【谷歌】【提出Vision Transformer】An image is worth 16x16 words Transformers for image recognition at scale.pdf)

[39.【2020】【ECCV】【Alexander Kolesnikov】【谷歌】【BiT重新审视了预训练+微调的模式，组合了一些已有的技术】Big Transfer (Bit) General Visual Representation Learning](C:\Users\Emoaya\Desktop\文章\精读文章\39.【2020】【ECCV】【Alexander Kolesnikov】【谷歌】【BiT重新审视了预训练+微调的模式，组合了一些已有的技术】Big Transfer (Bit) General Visual Representation Learning.pdf)

[40.【2019】【CVPR】【Guoliang Kang】【悉尼科技大学、谷歌、百度】【提出了CDD损失和CAN网络】Contrastive Adaptation Network for Unsupervised Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\40.【2019】【CVPR】【Guoliang Kang】【悉尼科技大学、谷歌、百度】【提出了CDD损失和CAN网络】Contrastive Adaptation Network for Unsupervised Domain Adaptation.pdf)

[41.【2021】【arXiv】【Atif Belal】【将知识蒸馏和DA结合】Knowledge Distillation Methods for Efficient Unsupervised Adaptation Across Multiple Domains](C:\Users\Emoaya\Desktop\文章\精读文章\41.【2021】【arXiv】【Atif Belal】【将知识蒸馏和DA结合】Knowledge Distillation Methods for Efficient Unsupervised Adaptation Across Multiple Domains.pdf)

[42.【2021】【arXiv】【Fabrizio J. Piva】【在语义分割中采用伪标签】Exploiting Image Translations via Ensemble Self-Supervised Learning for Unsupervised Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\42.【2021】【arXiv】【Fabrizio J. Piva】【在语义分割中采用伪标签】Exploiting Image Translations via Ensemble Self-Supervised Learning for Unsupervised Domain Adaptation.pdf)

[40.【2019】【CVPR】【Guoliang Kang】【悉尼科技大学、谷歌、百度】【提出了CDD损失和CAN网络】Contrastive Adaptation Network for Unsupervised Domain Adaptation](C:\Users\Emoaya\Desktop\文章\精读文章\40.【2019】【CVPR】【Guoliang Kang】【悉尼科技大学、谷歌、百度】【提出了CDD损失和CAN网络】Contrastive Adaptation Network for Unsupervised Domain Adaptation.pdf)

## 3. 第二名方法

**原文：**

[31.【2022】【NIPS比赛】【Chandramouli Rajagopalan】【第二名方法】 Final report](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【Chandramouli Rajagopalan】【第二名方法】 Final report.pdf)

[31.【2022】【NIPS比赛】【Chandramouli Rajagopalan】【第二名方法的PPT】 Final report](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【Chandramouli Rajagopalan】【第二名方法的PPT】 Final report.pdf)

**参考文献：**

## 4. 第三名方法

**原文：**

[31.【2022】【NIPS比赛】【Haojin Liao】【第三名方法】2nd Place Solution for VisDA 2021 Challenge Universally Domain Adaptive Image Recognition](C:\Users\Emoaya\Desktop\文章\精读文章\31.【2022】【NIPS比赛】【Haojin Liao】【第三名方法】2nd Place Solution for VisDA 2021 Challenge Universally Domain Adaptive Image Recognition.pdf)

**参考文献：**
