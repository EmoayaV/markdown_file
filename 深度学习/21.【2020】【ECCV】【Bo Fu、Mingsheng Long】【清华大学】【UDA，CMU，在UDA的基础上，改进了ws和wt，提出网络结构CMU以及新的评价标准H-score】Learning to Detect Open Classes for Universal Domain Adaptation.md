## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\21.【2020】【ECCV】【Bo Fu、Mingsheng Long】【清华大学】【UDA，CMU，在UDA的基础上，改进了ws和wt，提出网络结构CMU以及新的评价标准H-score】Learning to Detect Open Classes for Universal Domain Adaptation.pdf)

### 1.1 在干什么、有什么贡献、什么结论

**背景：目标域无监督。**

**两个大挑战：**1.域偏移（domain shift），在公共类别中去对齐源域和目标域的特征，2.类别偏移（category shift），如何分辨未知类（也就是分辨公共类别）。其中分辨未知类是最难的任务，如果可以正确分辨那么就可以用传统的DA方法进行训练。

**提出 Calibrated Multiple Uncertainties (CMU) 。**

**提出了一个新的评价指标，叫做H-score，是关于共享类和未知类的指标。**

**UAN的两个缺点：**

第一，UAN用熵去衡量不确定性，非对抗-域分类器来衡量域相似性（domain similarity）。但是熵对不确定的和尖锐的预测缺乏鉴别性，非对抗-域分类器的预测大多过于自信。

第二，未经校准的预测使其不可靠。UAN无法清楚地检测到目标域的未知类，这样分类误差就会藏在每个目标域的每个预测类别的概率中。

## 2.  校正后的多重不确定性Calibrated Multiple Uncertainties (CMU)

### 2.1  多层不确定性Multiple Uncertainties

首先采用UAN的假设：目标域公共类中的数据，比目标域私有类中的数据具有更低的不确定度。

然后对目标样本的不确定度进行排序，将不确定度最高的样本标记为目标域私有类数据。

**对不确定性的度量呢，作者给出了三种计算方式并进行比较：**

<img src="D:\markdown file\截图\image-20221026151927782.png" alt="image-20221026151927782" style="zoom:50%;" />

**熵（entropy）：在目标域公共类中，类别预测分布的熵小，在目标域私有类中，类别预测分布的熵大。**对于高度不确定和极其尖锐的预测，熵表现出较低的可区分性，什么意思呢？对于尖锐的概率分布，在有少数类别的情况下，这种熵的变化很明显，而对于尖锐的概率分布，在有少数类别的情况下，这种熵的变换就不明显了。<u>比如说有1024类，那么当分布是(1, 0, .., 0)时，entropy = 0，当分布是(0.5, 0.5, .., 0)时，entropy = log2 = 1，而当分布是(1/1024, 1/1024, .., 1/1024)时，entropy~max~ = log 1024=10。</u>当类别数较大时，这种差异可以忽略不计，但实际上，两种预测在不确定性方面有很大不同。因此，仅通过熵来估计不确定性将无法区分不确定的和极其尖锐的预测。

**置信度（confidence）：在目标域公共类中，置信度高，置信度的意思是当置信度=0.5时，表示该类别预测概率大于0.5我就认为预测正确 。**即使不同类别分布的置信度相同，其不确定程度也不同。<u>例如，当置信度为0.5，且最大概率为0.5时，其他两个概率可以为(0.5, 0)或(0.25, 0.25)。很明显，(0.5 ,0.5, 0)比(0.5, 0.25, 0.25)更不确定。</u>

**一致性（Consistency）：==一致性值越低，数据越有可能在目标域公共类中==。**因为所有分类器犯相同错误的概率低，这意味着所有不同的分类器错误地和巧合地预测样本到同一类中。我们采用多个不同分类器Σ~m~G~i~（m是不同分类器个数）来判断不确定性的一致性，这反映了不同分类器的一致性。分类器损失函数如下：

<img src="D:\markdown file\截图\image-20221026151914788.png" alt="image-20221026151914788" style="zoom:50%;" />

L是交叉熵损失。为了保持分类器的差异性，不进行对分类器G~i~进行反向传播，

**计算w~t~和w~s~：**

基于以上比较，我们可以得出结论，熵、置信度和一致性各有优缺点，不能单独表示不确定性。但是它们是相互补充的，并且可以协作来形成对所有类型的类分布具有高度可辨别性的不确定性测量。因此，我们选择三个标准的混合。对于每个分类器G~i~，(i = 1，…，m)预测源公共类C^s^上每个样本x的概率yi（包括源域和目标域的样本，x={x^s^, x^t^}，yi={yi^t^, yi^s^}） 。我们计算熵、置信度和一致性如下:

<img src="D:\markdown file\截图\image-20221026162247008.png" alt="image-20221026162247008" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221026162917839.png" alt="image-20221026162917839" style="zoom:50%;" />

y~ij~^t^ 表示第j类的概率，m表示分类器个数。

对于一个目标域样本x^t^，m个分类器一共有m个预测结果，为yi^t^(i = 1, 2, .., m)。

w~ent~就是m个分类器yi^t^熵，加起来再取平均。

w~conf~就是m个分类器的预测结果yi^t^中，预测概率最大的那一类，加起来再取平均。

w~cons~就是m个分类器的预测结果yi^t^中，将一个分类器的预测结果减去所有分类器预测结果的平均，再求平方；对m个分类器都执行上面的操作，在求和取平均；最后把所有类别的计算结果取绝对值相加，最后再除以类别数。实际上就是算了一个方差。

最后把上面几个权重相加，**w~t~(x~0~^t^)越大，证明对于目标域样本x~0~^t^来说，更像目标域公共类。**

<img src="D:\markdown file\截图\image-20221028130921440.png" alt="image-20221028130921440" style="zoom:50%;" />

我们将w~t~选择的常用数据的预测相加，以计算源类的权重V，V是基于类别的权重。V是当w~t~大于阈值w~0~的预测值y^^^的平均，对于源域的每一类的权重V~ys~，就是上面算的平均值中的一类。

### 2.2 不确定性校准Uncertainty Calibration

作者认为Ensemble是最适合UniDA的框架，并且已经嵌入到作者的框架中。

### 2.3 校正后的多重不确定性框架Calibrated Multiple Uncertainties framework(CMU)

**网络结构：**

<img src="D:\markdown file\截图\image-20221028125829285.png" alt="image-20221028125829285" style="zoom:50%;" />

**损失函数及优化：**

<img src="D:\markdown file\截图\image-20221028130428780.png" alt="image-20221028130428780" style="zoom:50%;" />

**预测：**

<img src="D:\markdown file\截图\image-20221028130458363.png" alt="image-20221028130458363" style="zoom:50%;" />

**H-score：**

<img src="D:\markdown file\截图\image-20221028130821489.png" alt="image-20221028130821489" style="zoom:50%;" />
