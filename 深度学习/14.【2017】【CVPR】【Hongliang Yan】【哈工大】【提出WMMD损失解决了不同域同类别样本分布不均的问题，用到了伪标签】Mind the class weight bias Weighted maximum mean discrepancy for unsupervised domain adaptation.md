## 1. 摘要abs和导言intro

[文章链接](C:\Users\Emoaya\Desktop\文章\精读文章\14.【2017】【CVPR】【Hongliang Yan】【哈工大】【提出WMMD损失解决了不同域同类别样本分布不均的问题，用到了伪标签】Mind the class weight bias Weighted maximum mean discrepancy for unsupervised domain adaptation.pdf)

### 1.1 在干什么、有什么贡献、什么结论

<img src="D:\markdown file\截图\image-20221010161726945.png" alt="image-20221010161726945" style="zoom: 67%;" />

**背景：目标域无监督**。如果完全没有标签信息，那要在实现域对齐的基础上实现语义对齐呢？现有部分方法采用了**伪标签**（pseudo label)实现无监督的DA。

**在干什么：**主要就是说MMD没有考虑源域和目标域之间的类先验概率分布的差异，简单来说就是源域和目标域同一类的样本数量有差异，作者称作类权重偏差（class weight bias），就是p~s~(y~s~) 和 p~t~(y~t~)不同，再简单说就是每一类的个数源域和目标域不一样。于是作者就提出了一种权重MMD（weighted MMD），也叫WMMD。

**WMMD的作用其实就是在MMD的基础上增加了类对齐。**

## 2. 具体算法

<img src="D:\markdown file\截图\image-20221011135204988.png" alt="image-20221011135204988" style="zoom:67%;" />

**问题：**一种类权重偏差（class weight bias）最极端的情况是目标域没有源域的类别，如图（a）所示，如果目标域没有源域的类别，那么使用传统的MMD算法虽然拉近源域和目标域的距离，但是由于类权重偏差（class weight bias），尽管目标域没有类3，分类器仍然会把目标域的类1的一部分样本分到源域中的类3。

<img src="D:\markdown file\截图\image-20221011153643537.png" alt="image-20221011153643537" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221011154446579.png" alt="image-20221011154446579" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221011154847464.png" alt="image-20221011154847464" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221011154551458.png" alt="image-20221011154551458" style="zoom:50%;" />

**公式：**p~u~(x^u^)是一个公式，u={s, t}，首先p~s~(x^s^)表示源域的数据分布，p~t~(x^t^)表示目标域的分布。如果说目标域是无标签的，那么传统的MMD就认为p~u~(x^u^) =  Σp~u~(x^u^|y^u^=c)，也就是只拉近了两个分布的距离，没有拉近不同分布同一类别的距离，就是说只使源域和目标域蓝线这部分分布相似。

**那么怎么消除类权重偏差（class weight bias）呢？**把公式（6）改成（7）即可。那么这个参数α~c~怎么理解呢？看（图b），源域有2个class1的样本，目标域有8个class1的样本，那么α~c~ = 8/2 = 4，就是说源域的class1的样本要变成2*α~c~ = 8个，这就实现了类权重偏差（class weight bias）的消除。

图（b）是基于本文提出的加权MMD方法的，可以看到作者对源域中每个类别均赋予了一个**辅助权重（**红色数字），这个权重的引入使得源域的类别比例约等于目标域中的类别比例。接着，作者使用加权后的源域与目标域进行MMD，实现DA。

**最终的WMMD如公式（8）。**

<img src="D:\markdown file\截图\image-20221011161223057.png" alt="image-20221011161223057" style="zoom:50%;" />

<img src="D:\markdown file\截图\image-20221011163845859.png" alt="image-20221011163845859" style="zoom:50%;" />

**重点：目标域没有标签，如何知道目标域每个类有多少样本？如何对源域的样本进行增减？**

首先把网络在源域上训练好，再固定网络参数，把目标域的样本放入网络，得到分类结果，把概率最大的分类结果当作目标域样本的标签，这时的标签叫做伪标签（pseudo-label）如公式（12）（13）所示。

这时就可以计算出目标域的先验概率 w~c~^t^ = p~t~ (y^t^ = c)，所谓的先验概率实际就是数个数，数单一类别的样本站总样本的比例，如公式（14）所示。

接下来再计算辅助权重α~c~ = w~c~^t^ / w~c~^s^ ，带入损失函数用SGD更新即可。

==实际上这个方法是有缺点的：==

==1.增加源域某一类样本仅仅用原样本的复制就行了？能不能用数据增强的方式，或者生成对抗模型生成与原样本相似的样本来作为其复制。==

==2.网络是在源域上训练好的，如何保证目标域样本输入网络产生的伪标签就是准确的呢？==

